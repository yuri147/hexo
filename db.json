{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1489120380286},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1489120380286},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1489120380286},{"_id":"themes/next/.gitignore","hash":"5f09fca02e030b7676c1d312cd88ce8fbccf381c","modified":1489120380286},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1489120380286},{"_id":"themes/next/.javascript_ignore","hash":"f9ea3c5395f8feb225a24e2c32baa79afda30c16","modified":1489120380286},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1489120380286},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1489120380286},{"_id":"themes/next/.travis.yml","hash":"c42d9608c8c7fe90de7b1581a8dc3886e90c179e","modified":1489120380286},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1489120380286},{"_id":"themes/next/README.en.md","hash":"4ece25ee5f64447cd522e54cb0fffd9a375f0bd4","modified":1489120380286},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1489120380286},{"_id":"themes/next/_config.yml","hash":"fa2c99cd035add48d9275fe70c6b9c182294b881","modified":1489128148284},{"_id":"themes/next/bower.json","hash":"5abc236d9cc2512f5457ed57c1fba76669eb7399","modified":1489120380286},{"_id":"themes/next/gulpfile.coffee","hash":"933e6d29eb82522cff0df209d52b935e91b1111c","modified":1489120380286},{"_id":"themes/next/package.json","hash":"7e87b2621104b39a30488654c2a8a0c6a563574b","modified":1489120380298},{"_id":"source/categories/index.md","hash":"128c3c497924130f54f084b29e1aacaa32d2cfb2","modified":1489124086661},{"_id":"source/_posts/bp.md","hash":"e2a460d60f8188c64ff32bca43156d5ee0434473","modified":1490752373963},{"_id":"source/tags/index.md","hash":"1ffad8e05a02d3724759a07e57a74fb377501967","modified":1489127503404},{"_id":"themes/next/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1489120380234},{"_id":"themes/next/.git/config","hash":"91b6a53b2a7f929b698734717a38d4ac169f0c1f","modified":1489120380238},{"_id":"themes/next/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1489119763628},{"_id":"themes/next/.git/index","hash":"7ec4116d8e30f680fbb5d39435c81a826b308ba7","modified":1489139461513},{"_id":"themes/next/.git/packed-refs","hash":"547f7c5e2791e36cc09c2444d3a4a65fe5468d12","modified":1489120380234},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5ab257af816986cd0e53f9527a92d5934ac70ae9","modified":1489120380286},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"c2024ded82143807c28a299c5fe6b927ef3525ff","modified":1489120380286},{"_id":"themes/next/languages/de.yml","hash":"1fdea1f84b7f691f5b4dd4d2b43eeb27b10fa0c8","modified":1489120380286},{"_id":"themes/next/languages/en.yml","hash":"95ec5cdfb563854f231b76162a3494f6ecc5bf61","modified":1489120380286},{"_id":"themes/next/languages/default.yml","hash":"95ec5cdfb563854f231b76162a3494f6ecc5bf61","modified":1489120380286},{"_id":"themes/next/languages/fr-FR.yml","hash":"e98f1558347752a20019b71f0b1f9c8be1b34f42","modified":1489120380286},{"_id":"themes/next/languages/id.yml","hash":"34396bef27c4ab9e9a3c5d3e3aa94b0e3b3a7b0d","modified":1489120380286},{"_id":"themes/next/languages/ja.yml","hash":"49f12149edcc1892b26a6207328cda64da20116d","modified":1489120380286},{"_id":"themes/next/languages/ko.yml","hash":"b6bc5d6b0c000deb44099b42d3aebb8c49dbfca9","modified":1489120380286},{"_id":"themes/next/languages/pt-BR.yml","hash":"7742ba4c0d682cbe1d38305332ebc928abd754b5","modified":1489120380290},{"_id":"themes/next/languages/pt.yml","hash":"6b660b117314cad93f08757601df3adb04c68beb","modified":1489120380290},{"_id":"themes/next/languages/ru.yml","hash":"5022885d8955e1b91d8841048db272bf99c59a76","modified":1489120380290},{"_id":"themes/next/languages/zh-Hans.yml","hash":"40d01dc46d57f71c2ef635c45b295d4355456e90","modified":1489120380290},{"_id":"themes/next/languages/zh-hk.yml","hash":"19c23d21f262e24c06ee6ddfd51d2a6585304f88","modified":1489120380290},{"_id":"themes/next/languages/zh-tw.yml","hash":"68407799271c78ecc07f03d238257dd8c65ad42d","modified":1489120380290},{"_id":"themes/next/layout/_layout.swig","hash":"2c0c3547a5b470024326a33ae2779d5ee0252266","modified":1489120380290},{"_id":"themes/next/layout/archive.swig","hash":"b5b59d70fc1563f482fa07afd435752774ad5981","modified":1489120380294},{"_id":"themes/next/layout/category.swig","hash":"6422d196ceaff4220d54b8af770e7e957f3364ad","modified":1489120380298},{"_id":"themes/next/layout/index.swig","hash":"427d0b95b854e311ae363088ab39a393bf8fdc8b","modified":1489120380298},{"_id":"themes/next/layout/page.swig","hash":"3727fab9dadb967e9c2204edca787dc72264674a","modified":1489120380298},{"_id":"themes/next/layout/post.swig","hash":"e2e512142961ddfe77eba29eaa88f4a2ee43ae18","modified":1489120380298},{"_id":"themes/next/layout/schedule.swig","hash":"1f1cdc268f4ef773fd3ae693bbdf7d0b2f45c3a3","modified":1489120380298},{"_id":"themes/next/layout/tag.swig","hash":"07cf49c49c39a14dfbe9ce8e7d7eea3d4d0a4911","modified":1489120380298},{"_id":"themes/next/scripts/merge-configs.js","hash":"13c8b3a2d9fce06c2488820d9248d190c8100e0a","modified":1489120380298},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1489120380298},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1489120380362},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1489120380362},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1489120380362},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489120380310},{"_id":"source/js/bp/bpdemo.js","hash":"2b055752842d4d9f67de671df4719c10392bfa99","modified":1490698605000},{"_id":"themes/next/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1489119763628},{"_id":"themes/next/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1489119763628},{"_id":"themes/next/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1489119763628},{"_id":"themes/next/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1489119763628},{"_id":"themes/next/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1489119763628},{"_id":"themes/next/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1489119763628},{"_id":"themes/next/.git/hooks/pre-rebase.sample","hash":"18be3eb275c1decd3614e139f5a311b75f1b0ab8","modified":1489119763628},{"_id":"themes/next/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1489119763628},{"_id":"themes/next/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1489119763628},{"_id":"themes/next/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1489119763628},{"_id":"themes/next/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1489119763628},{"_id":"themes/next/.git/logs/HEAD","hash":"64f8dcd7443154cf478c80afde8c18a5d9854682","modified":1489120380234},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1489120380290},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1489120380290},{"_id":"themes/next/layout/_macro/post.swig","hash":"2c2efe44ea013030f3ce5da7bfdeddb74489eb6e","modified":1489120380290},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"5864f5567ba5efeabcf6ea355013c0b603ee07f2","modified":1489120380290},{"_id":"themes/next/layout/_macro/reward.swig","hash":"37e5b7c42ec17b9b6b786c5512bcc481a21c974e","modified":1489120380290},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"911b99ba0445b2c07373128d87a4ef2eb7de341a","modified":1489120380290},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"14e785adeb0e671ba0ff9a553e6f0d8def6c670c","modified":1489120380290},{"_id":"themes/next/layout/_partials/comments.swig","hash":"970aa668680896262b1056bb5787fc9ec8754495","modified":1489120380290},{"_id":"themes/next/layout/_partials/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1489120380290},{"_id":"themes/next/layout/_partials/footer.swig","hash":"7172c6053118b7c291a56a7860128a652ae66b83","modified":1489120380290},{"_id":"themes/next/layout/_partials/head.swig","hash":"a0eafe24d1dae30c790ae35612154b3ffbbd5cce","modified":1489120380290},{"_id":"themes/next/layout/_partials/header.swig","hash":"a1ffbb691dfad3eaf2832a11766e58a179003b8b","modified":1489120380290},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1489120380290},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1489120380290},{"_id":"themes/next/layout/_partials/search.swig","hash":"7b61e96508df70152b809ea5354236ab7f0d54f4","modified":1489120380290},{"_id":"themes/next/layout/_scripts/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1489120380294},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1489120380294},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1489120380294},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"4512867d80d9eddfc3a0f5fea3c456f33aa9d522","modified":1489120380294},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1489120380298},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1489120380298},{"_id":"themes/next/scripts/tags/exturl.js","hash":"79378f3a1cd90518b07808ed09156a3ab55ffa31","modified":1489120380298},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1489120380298},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1489120380298},{"_id":"themes/next/scripts/tags/note.js","hash":"6752925eedbdb939d8ec4d11bdfb75199f18dd70","modified":1489120380298},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1489120380310},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1489120380310},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1489120380310},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1489120380310},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1489120380310},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1489120380310},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1489120380310},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1489120380310},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1489120380310},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1489120380314},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1489120380314},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1489120380314},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1489120380314},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1489120380314},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1489120380314},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489120380294},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489120380294},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489120380306},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489120380306},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489120380306},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489120380310},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489120380310},{"_id":"themes/next/.git/refs/heads/master","hash":"8e263f0e3c466c2948b5c2b1e849c404b26898af","modified":1489120380234},{"_id":"themes/next/layout/_components/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1489120380290},{"_id":"themes/next/layout/_components/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1489120380290},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1489120380290},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1489120380290},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"2d1075f4cabcb3956b7b84a8e210f5a66f0a5562","modified":1489120380290},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1489120380294},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1489120380294},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1489120380294},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1489120380294},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1489120380294},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1489120380294},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1489120380294},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/analytics.swig","hash":"e46900412e28f529c26e25e6bada342006435a32","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/comments.swig","hash":"a279e1881208aff2f669fe235e9661ab825bc540","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/lean-analytics.swig","hash":"92dc60821307fc9769bea9b2d60adaeb798342af","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/localsearch.swig","hash":"f4dbd4c896e6510ded8ebe05394c28f8a86e71bf","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1489120380294},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1489120380306},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"715d5b40dc52f319fe4bff0325beb874774d9bd9","modified":1489120380306},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"78a83c38f69a8747bb74e420e6c9eeef1ea76525","modified":1489120380306},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1489120380310},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"06f432f328a5b8a9ef0dbd5301b002aba600b4ce","modified":1489120380310},{"_id":"themes/next/source/css/_variables/base.styl","hash":"e7c76d93605e2b685274400afe51c55cc651486e","modified":1489120380310},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1489120380314},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"aab7be0a6e2724b3faa9338db93c19556c559625","modified":1489120380314},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1489120380314},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1489120380314},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1489120380314},{"_id":"themes/next/source/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1489120380314},{"_id":"themes/next/source/js/src/post-details.js","hash":"3b2d64c2e6ae072ba2a9ebf7f09908a1543abd58","modified":1489120380314},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1489120380314},{"_id":"themes/next/source/js/src/utils.js","hash":"e13c9ccf70d593bdf3b8cc1d768f595abd610e6e","modified":1489120380314},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1489120380314},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1489120380322},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1489120380322},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1489120380322},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1489120380326},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1489120380326},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1489120380326},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1489120380326},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1489120380326},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1489120380326},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1489120380326},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1489120380330},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1489120380330},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1489120380350},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1489120380354},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1489120380354},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1489120380354},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1489120380354},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1489120380354},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1489120380354},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1489120380354},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1489120380354},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1489120380362},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1489120380362},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1489120380362},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1489120380354},{"_id":"themes/next/.git/logs/refs/heads/master","hash":"64f8dcd7443154cf478c80afde8c18a5d9854682","modified":1489120380234},{"_id":"themes/next/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1489120380234},{"_id":"themes/next/layout/_scripts/third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/analytics/busuanzi-counter.swig","hash":"4fcbf57c4918528ab51d3d042cff92cf5aefb599","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/analytics/facebook-sdk.swig","hash":"394d008e5e94575280407ad8a1607a028026cbc3","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/analytics/tencent-mta.swig","hash":"a652f202bd5b30c648c228ab8f0e997eb4928e44","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/comments/disqus.swig","hash":"fb1d04ede838b52ca7541973f86c3810f1ad396e","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/comments/gentie.swig","hash":"03592d1d731592103a41ebb87437fe4b0a4c78ca","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/comments/livere.swig","hash":"7240f2e5ec7115f8abbbc4c9ef73d4bed180fdc7","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1489120380294},{"_id":"themes/next/layout/_scripts/third-party/comments/youyan.swig","hash":"af9dd8a4aed7d06cf47b363eebff48850888566c","modified":1489120380294},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"59ad08bcc6fe9793594869ac2b4c525021453e78","modified":1489120380298},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"ef089a407c90e58eca10c49bc47ec978f96e03ba","modified":1489120380298},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1489120380298},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1489120380298},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1489120380298},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1489120380302},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1489120380306},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"7804e31c44717c9a9ddf0f8482b9b9c1a0f74538","modified":1489120380306},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1489120380306},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1489120380306},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"013619c472c7e4b08311c464fcbe9fcf5edde603","modified":1489120380306},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1489120380310},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1489120380310},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"f15537cee1a9ef4fa1e72a1670ebce4097db8115","modified":1489120380310},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1489120380310},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1489120380310},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"e3e23751d4ad24e8714b425d768cf68e37de7ded","modified":1489120380310},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1489120380310},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1489120380314},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1489120380322},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1489120380322},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1489120380322},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1489120380322},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1489120380322},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1489120380322},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1489120380326},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1489120380326},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1489120380326},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1489120380326},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1489120380326},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1489120380330},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1489120380330},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1489120380330},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1489120380354},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1489120380354},{"_id":"themes/next/.git/objects/pack/pack-a95573b69ce446566225c894464cba61f7e57293.idx","hash":"3903b3385c6affbb99188c8f10c2f0794fcd7a05","modified":1489120380198},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1489120380350},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1489120380350},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1489120380358},{"_id":"themes/next/.git/logs/refs/remotes/origin/HEAD","hash":"64f8dcd7443154cf478c80afde8c18a5d9854682","modified":1489120380234},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1489120380298},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1489120380298},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1489120380298},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"755b04edbbfbdd981a783edb09c9cc34cb79cea7","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"beccb53dcd658136fb91a0c5678dea8f37d6e0b6","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"8fae54591877a73dff0b29b2be2e8935e3c63575","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"b25132fe6a7ad67059a2c3afc60feabb479bdd75","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"b9a2e76f019a5941191f1263b54aef7b69c48789","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"e792c8dc41561c96d128e9b421187f1c3dc978a0","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"bfd806d0a9f21446a22df82ac02e37d0075cc3b5","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"2e7ec9aaa3293941106b1bdd09055246aa3c3dc6","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"5f6ea57aabfa30a437059bf8352f1ad829dbd4ff","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"7690b9596ec3a49befbe529a5a2649abec0faf76","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a2ec22ef4a6817bbb2abe8660fcd99fe4ca0cc5e","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"234facd038f144bd0fe09a31ed1357c5d74c517f","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1489120380306},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1489120380302},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1489120380306},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1489120380306},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"74d0ba86f698165d13402670382a822c8736a556","modified":1489120380306},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"8fe1e55bc290e6aaf07cc644fe27b62107a272a8","modified":1489120380306},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1489120380306},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1489120380306},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1489120380306},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1489120380306},{"_id":"themes/next/source/css/_common/components/third-party/gentie.styl","hash":"586a3ec0f1015e7207cd6a2474362e068c341744","modified":1489120380306},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1489120380306},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"173490e21bece35a34858e8e534cf86e34561350","modified":1489120380306},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"42348219db93a85d2ee23cb06cebd4d8ab121726","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1489120380306},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1489120380310},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1489120380322},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1489120380322},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1489120380326},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1489120380326},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1489120380326},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1489120380326},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1489120380334},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1489120380338},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1489120380350},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1489120380322},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1489120380346},{"_id":"themes/next/.git/objects/pack/pack-a95573b69ce446566225c894464cba61f7e57293.pack","hash":"3e3ac201472e4a0454af57a6dddf7ee59436b224","modified":1489120380190}],"Category":[{"name":"Tech","_id":"cj0ubhjyu00037u8g0p29lrbn"}],"Data":[],"Page":[{"title":"categories","date":"2017-03-10T05:34:20.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2017-03-10 13:34:20\ntype: \"categories\"\ncomments: false\n---\n","updated":"2017-03-10T05:34:46.661Z","path":"categories/index.html","layout":"page","_id":"cj0ubhjyd00017u8g7j64lvf6","content":"","excerpt":"","more":""},{"title":"tags","date":"2017-03-10T05:33:03.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2017-03-10 13:33:03\ntype: \"tags\"\ncomments: false\n---","updated":"2017-03-10T06:31:43.404Z","path":"tags/index.html","layout":"page","_id":"cj0ubhjyk00027u8gmi6a491e","content":"","excerpt":"","more":""},{"_content":"var Neural = function() {\n\t//神经网络维度\n\tvar v = 2;\n\t//训练目标\n\tvar t = [0.01, 0.99];\n\t//输入层\n\tvar i = [0.15, 0.1];\n\t//输出层\n\tvar o = [];\n\t//隐含层\n\tvar h = [];\n\t//权值\n\tvar w = [\n\t\t[0.1, 0.2, 0.15, 0.25],\n\t\t[0.3, 0.35, 0.4, 0.45]\n\t];\n\t//调整之后的权值\n\tvar nW = [\n\t\t[],\n\t\t[]\n\t];\n\t//误差\n\tvar e = [];\n\t//总误差\n\tvar te = 0;\n\t//偏置项权值\n\tvar b = [0.35, 0.6];\n\t//学习率\n\tvar lr = 0.5;\n\n\tvar self = this;\n\t//激活函数\n\tthis.sigmoid = function(z) {\n\t\treturn 1 / (1 + Math.exp(-z));\n\t}\n\n\t//平方误差函数\n\tthis.squareErr = function(target, current) {\n\t\treturn 0.5 * Math.pow((target - current), 2);\n\t}\n\n\t//前向传播\n\tthis.forward = function() {\n\t\t//隐含层\n\t\tfor (var x = 0; x < i.length; x++) {\n\t\t\th[x] = self.sigmoid(i[0] * w[0][x * v] + i[1] * w[0][x * v + 1] + b[0]);\n\t\t}\n\t\t//输出层\n\t\tfor (var y = 0; y < i.length; y++) {\n\t\t\to[y] = self.sigmoid(h[0] * w[1][y * v] + h[1] * w[1][y * v + 1] + b[1]);\n\t\t}\n\t\tself.o=o;\n\t}\n\n\t//计算总误差\n\tthis.totalError = function() {\n\t\tfor (var x = 0; x < t.length; x++) {\n\t\t\te[x] = self.squareErr(t[x], o[x]);\n\t\t\tte += e[x];\n\t\t}\n\t}\n\n\t//反向传播第一层\n\tthis.backward1 = function() {\n\t\tfor (var y = 0; y < t.length; y++) {\n\t\t\tfor (var x = 0; x < h.length; x++) {\n\t\t\t\tvar selfEffect = -1 * (t[y] - o[y]) * o[y] * (1 - o[y]) * h[x];\n\t\t\t\tnW[1][x + y * v] = w[1][x + y * v] - lr * selfEffect;\n\t\t\t\t// console.info('w' + parseInt(5 + x + y * v) + \"权重变化: \" + w[1][x + y * v] + \" => \" + nW[1][x + y * v]);\n\t\t\t}\n\t\t}\n\t}\n\n\t//反向传播第二层\n\tthis.backward2 = function() {\n\t\tvar f_1 = [];\n\t\tvar f_2 = 0;\n\t\tvar f_3 = 0;\n\t\tvar _f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][0];\n\t\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][2];\n\t\tf_1.push(_f_1);\n\t\t_f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][1];\n\t\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][3];\n\t\tf_1.push(_f_1);\n\t\tfor (var y = 0; y < h.length; y++) {\n\t\t\tf_2 = h[y] * (1 - h[y]);\n\t\t\tfor (var z = 0; z < i.length; z++) {\n\t\t\t\tf_3 = i[z];\n\t\t\t\tnW[0][y + z * v] = w[0][y + z * v] - lr * (f_1[y] * f_2 * f_3);\n\t\t\t\t// console.info('w' + parseInt(y + z * v) + \"权重变化: \" + w[1][y + z * v] + \" => \" + nW[1][y + z * v]);\n\t\t\t}\n\t\t}\n\t\tw = nW;\n\t};\n};\n\n\n\n\nvar test = new Neural();\nvar final_o=[];\nfor (var i = 0; i < 10000; i++) {\n\ttest.forward();\n\tvar old_o=[].concat(test.o);\n\ttest.totalError();\n\ttest.backward1();\n\ttest.backward2();\n\ttest.forward();\n\tfinal_o=[].concat(test.o);\n\t// console.info('预测值变化：'+old_o +\" => \"+test.o);\n\t\n}\nconsole.info('最终预测值：'+final_o);\n// console.info(te);\n// console.info(nW);\n","source":"js/bp/bpdemo.js","raw":"var Neural = function() {\n\t//神经网络维度\n\tvar v = 2;\n\t//训练目标\n\tvar t = [0.01, 0.99];\n\t//输入层\n\tvar i = [0.15, 0.1];\n\t//输出层\n\tvar o = [];\n\t//隐含层\n\tvar h = [];\n\t//权值\n\tvar w = [\n\t\t[0.1, 0.2, 0.15, 0.25],\n\t\t[0.3, 0.35, 0.4, 0.45]\n\t];\n\t//调整之后的权值\n\tvar nW = [\n\t\t[],\n\t\t[]\n\t];\n\t//误差\n\tvar e = [];\n\t//总误差\n\tvar te = 0;\n\t//偏置项权值\n\tvar b = [0.35, 0.6];\n\t//学习率\n\tvar lr = 0.5;\n\n\tvar self = this;\n\t//激活函数\n\tthis.sigmoid = function(z) {\n\t\treturn 1 / (1 + Math.exp(-z));\n\t}\n\n\t//平方误差函数\n\tthis.squareErr = function(target, current) {\n\t\treturn 0.5 * Math.pow((target - current), 2);\n\t}\n\n\t//前向传播\n\tthis.forward = function() {\n\t\t//隐含层\n\t\tfor (var x = 0; x < i.length; x++) {\n\t\t\th[x] = self.sigmoid(i[0] * w[0][x * v] + i[1] * w[0][x * v + 1] + b[0]);\n\t\t}\n\t\t//输出层\n\t\tfor (var y = 0; y < i.length; y++) {\n\t\t\to[y] = self.sigmoid(h[0] * w[1][y * v] + h[1] * w[1][y * v + 1] + b[1]);\n\t\t}\n\t\tself.o=o;\n\t}\n\n\t//计算总误差\n\tthis.totalError = function() {\n\t\tfor (var x = 0; x < t.length; x++) {\n\t\t\te[x] = self.squareErr(t[x], o[x]);\n\t\t\tte += e[x];\n\t\t}\n\t}\n\n\t//反向传播第一层\n\tthis.backward1 = function() {\n\t\tfor (var y = 0; y < t.length; y++) {\n\t\t\tfor (var x = 0; x < h.length; x++) {\n\t\t\t\tvar selfEffect = -1 * (t[y] - o[y]) * o[y] * (1 - o[y]) * h[x];\n\t\t\t\tnW[1][x + y * v] = w[1][x + y * v] - lr * selfEffect;\n\t\t\t\t// console.info('w' + parseInt(5 + x + y * v) + \"权重变化: \" + w[1][x + y * v] + \" => \" + nW[1][x + y * v]);\n\t\t\t}\n\t\t}\n\t}\n\n\t//反向传播第二层\n\tthis.backward2 = function() {\n\t\tvar f_1 = [];\n\t\tvar f_2 = 0;\n\t\tvar f_3 = 0;\n\t\tvar _f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][0];\n\t\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][2];\n\t\tf_1.push(_f_1);\n\t\t_f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][1];\n\t\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][3];\n\t\tf_1.push(_f_1);\n\t\tfor (var y = 0; y < h.length; y++) {\n\t\t\tf_2 = h[y] * (1 - h[y]);\n\t\t\tfor (var z = 0; z < i.length; z++) {\n\t\t\t\tf_3 = i[z];\n\t\t\t\tnW[0][y + z * v] = w[0][y + z * v] - lr * (f_1[y] * f_2 * f_3);\n\t\t\t\t// console.info('w' + parseInt(y + z * v) + \"权重变化: \" + w[1][y + z * v] + \" => \" + nW[1][y + z * v]);\n\t\t\t}\n\t\t}\n\t\tw = nW;\n\t};\n};\n\n\n\n\nvar test = new Neural();\nvar final_o=[];\nfor (var i = 0; i < 10000; i++) {\n\ttest.forward();\n\tvar old_o=[].concat(test.o);\n\ttest.totalError();\n\ttest.backward1();\n\ttest.backward2();\n\ttest.forward();\n\tfinal_o=[].concat(test.o);\n\t// console.info('预测值变化：'+old_o +\" => \"+test.o);\n\t\n}\nconsole.info('最终预测值：'+final_o);\n// console.info(te);\n// console.info(nW);\n","date":"2017-03-28T10:56:45.504Z","updated":"2017-03-28T10:56:45.000Z","path":"js/bp/bpdemo.js","layout":"false","title":"","comments":1,"_id":"cj0ubhkik00097u8g6obgb4bk","content":"var Neural = function() {\n\t//神经网络维度\n\tvar v = 2;\n\t//训练目标\n\tvar t = [0.01, 0.99];\n\t//输入层\n\tvar i = [0.15, 0.1];\n\t//输出层\n\tvar o = [];\n\t//隐含层\n\tvar h = [];\n\t//权值\n\tvar w = [\n\t\t[0.1, 0.2, 0.15, 0.25],\n\t\t[0.3, 0.35, 0.4, 0.45]\n\t];\n\t//调整之后的权值\n\tvar nW = [\n\t\t[],\n\t\t[]\n\t];\n\t//误差\n\tvar e = [];\n\t//总误差\n\tvar te = 0;\n\t//偏置项权值\n\tvar b = [0.35, 0.6];\n\t//学习率\n\tvar lr = 0.5;\n\n\tvar self = this;\n\t//激活函数\n\tthis.sigmoid = function(z) {\n\t\treturn 1 / (1 + Math.exp(-z));\n\t}\n\n\t//平方误差函数\n\tthis.squareErr = function(target, current) {\n\t\treturn 0.5 * Math.pow((target - current), 2);\n\t}\n\n\t//前向传播\n\tthis.forward = function() {\n\t\t//隐含层\n\t\tfor (var x = 0; x < i.length; x++) {\n\t\t\th[x] = self.sigmoid(i[0] * w[0][x * v] + i[1] * w[0][x * v + 1] + b[0]);\n\t\t}\n\t\t//输出层\n\t\tfor (var y = 0; y < i.length; y++) {\n\t\t\to[y] = self.sigmoid(h[0] * w[1][y * v] + h[1] * w[1][y * v + 1] + b[1]);\n\t\t}\n\t\tself.o=o;\n\t}\n\n\t//计算总误差\n\tthis.totalError = function() {\n\t\tfor (var x = 0; x < t.length; x++) {\n\t\t\te[x] = self.squareErr(t[x], o[x]);\n\t\t\tte += e[x];\n\t\t}\n\t}\n\n\t//反向传播第一层\n\tthis.backward1 = function() {\n\t\tfor (var y = 0; y < t.length; y++) {\n\t\t\tfor (var x = 0; x < h.length; x++) {\n\t\t\t\tvar selfEffect = -1 * (t[y] - o[y]) * o[y] * (1 - o[y]) * h[x];\n\t\t\t\tnW[1][x + y * v] = w[1][x + y * v] - lr * selfEffect;\n\t\t\t\t// console.info('w' + parseInt(5 + x + y * v) + \"权重变化: \" + w[1][x + y * v] + \" => \" + nW[1][x + y * v]);\n\t\t\t}\n\t\t}\n\t}\n\n\t//反向传播第二层\n\tthis.backward2 = function() {\n\t\tvar f_1 = [];\n\t\tvar f_2 = 0;\n\t\tvar f_3 = 0;\n\t\tvar _f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][0];\n\t\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][2];\n\t\tf_1.push(_f_1);\n\t\t_f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][1];\n\t\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][3];\n\t\tf_1.push(_f_1);\n\t\tfor (var y = 0; y < h.length; y++) {\n\t\t\tf_2 = h[y] * (1 - h[y]);\n\t\t\tfor (var z = 0; z < i.length; z++) {\n\t\t\t\tf_3 = i[z];\n\t\t\t\tnW[0][y + z * v] = w[0][y + z * v] - lr * (f_1[y] * f_2 * f_3);\n\t\t\t\t// console.info('w' + parseInt(y + z * v) + \"权重变化: \" + w[1][y + z * v] + \" => \" + nW[1][y + z * v]);\n\t\t\t}\n\t\t}\n\t\tw = nW;\n\t};\n};\n\n\n\n\nvar test = new Neural();\nvar final_o=[];\nfor (var i = 0; i < 10000; i++) {\n\ttest.forward();\n\tvar old_o=[].concat(test.o);\n\ttest.totalError();\n\ttest.backward1();\n\ttest.backward2();\n\ttest.forward();\n\tfinal_o=[].concat(test.o);\n\t// console.info('预测值变化：'+old_o +\" => \"+test.o);\n\t\n}\nconsole.info('最终预测值：'+final_o);\n// console.info(te);\n// console.info(nW);\n","excerpt":"","more":"var Neural = function() {\n\t//神经网络维度\n\tvar v = 2;\n\t//训练目标\n\tvar t = [0.01, 0.99];\n\t//输入层\n\tvar i = [0.15, 0.1];\n\t//输出层\n\tvar o = [];\n\t//隐含层\n\tvar h = [];\n\t//权值\n\tvar w = [\n\t\t[0.1, 0.2, 0.15, 0.25],\n\t\t[0.3, 0.35, 0.4, 0.45]\n\t];\n\t//调整之后的权值\n\tvar nW = [\n\t\t[],\n\t\t[]\n\t];\n\t//误差\n\tvar e = [];\n\t//总误差\n\tvar te = 0;\n\t//偏置项权值\n\tvar b = [0.35, 0.6];\n\t//学习率\n\tvar lr = 0.5;\n\n\tvar self = this;\n\t//激活函数\n\tthis.sigmoid = function(z) {\n\t\treturn 1 / (1 + Math.exp(-z));\n\t}\n\n\t//平方误差函数\n\tthis.squareErr = function(target, current) {\n\t\treturn 0.5 * Math.pow((target - current), 2);\n\t}\n\n\t//前向传播\n\tthis.forward = function() {\n\t\t//隐含层\n\t\tfor (var x = 0; x < i.length; x++) {\n\t\t\th[x] = self.sigmoid(i[0] * w[0][x * v] + i[1] * w[0][x * v + 1] + b[0]);\n\t\t}\n\t\t//输出层\n\t\tfor (var y = 0; y < i.length; y++) {\n\t\t\to[y] = self.sigmoid(h[0] * w[1][y * v] + h[1] * w[1][y * v + 1] + b[1]);\n\t\t}\n\t\tself.o=o;\n\t}\n\n\t//计算总误差\n\tthis.totalError = function() {\n\t\tfor (var x = 0; x < t.length; x++) {\n\t\t\te[x] = self.squareErr(t[x], o[x]);\n\t\t\tte += e[x];\n\t\t}\n\t}\n\n\t//反向传播第一层\n\tthis.backward1 = function() {\n\t\tfor (var y = 0; y < t.length; y++) {\n\t\t\tfor (var x = 0; x < h.length; x++) {\n\t\t\t\tvar selfEffect = -1 * (t[y] - o[y]) * o[y] * (1 - o[y]) * h[x];\n\t\t\t\tnW[1][x + y * v] = w[1][x + y * v] - lr * selfEffect;\n\t\t\t\t// console.info('w' + parseInt(5 + x + y * v) + \"权重变化: \" + w[1][x + y * v] + \" => \" + nW[1][x + y * v]);\n\t\t\t}\n\t\t}\n\t}\n\n\t//反向传播第二层\n\tthis.backward2 = function() {\n\t\tvar f_1 = [];\n\t\tvar f_2 = 0;\n\t\tvar f_3 = 0;\n\t\tvar _f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][0];\n\t\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][2];\n\t\tf_1.push(_f_1);\n\t\t_f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][1];\n\t\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][3];\n\t\tf_1.push(_f_1);\n\t\tfor (var y = 0; y < h.length; y++) {\n\t\t\tf_2 = h[y] * (1 - h[y]);\n\t\t\tfor (var z = 0; z < i.length; z++) {\n\t\t\t\tf_3 = i[z];\n\t\t\t\tnW[0][y + z * v] = w[0][y + z * v] - lr * (f_1[y] * f_2 * f_3);\n\t\t\t\t// console.info('w' + parseInt(y + z * v) + \"权重变化: \" + w[1][y + z * v] + \" => \" + nW[1][y + z * v]);\n\t\t\t}\n\t\t}\n\t\tw = nW;\n\t};\n};\n\n\n\n\nvar test = new Neural();\nvar final_o=[];\nfor (var i = 0; i < 10000; i++) {\n\ttest.forward();\n\tvar old_o=[].concat(test.o);\n\ttest.totalError();\n\ttest.backward1();\n\ttest.backward2();\n\ttest.forward();\n\tfinal_o=[].concat(test.o);\n\t// console.info('预测值变化：'+old_o +\" => \"+test.o);\n\t\n}\nconsole.info('最终预测值：'+final_o);\n// console.info(te);\n// console.info(nW);\n"}],"Post":[{"title":"超酷的反向传播算法","_content":"<h2 id='id1' >人工智能</h2>\n  &emsp;&emsp;目前最火的技术莫过于人工智能，或者说机器学习。从IBM Watson到Google AlphaGo,人工智能仿佛已经冲出了实验室，在实际生活中发挥作用。面对如此高大上的技术，普通老百姓要如何去看待它，理解它的本质呢?沉着冷静别惊慌，本文将尽可能给你一个答案。\n  \n  &emsp;&emsp;首先要知道机器学习的本质是算法，这里就会有好几种，比如：神经网络、支持向量机、朴素贝叶斯等等一堆。虽然算法很多，但他们主要解决的都是同一个问题---分类预测问题。为什么分类预测问题这么重要？因为机器学习的本质是重现人类学习的过程，这个过程可以大致分为两部分：1.定义一个事物，2.判断一个事物。如果一个机器可以对一个事物进行判断，判断的结果与人类的判断相似，那它近似的就是一个人工智能。\n\n  &emsp;&emsp;假设这样一个场景，我和机器都看到了一个苹果，按照之前对机器的训练如果他告诉我他看到了一个苹果，那说明这个机器是具有一定人工智能的，如果它还能告诉我这个苹果的产地，成熟度，净重，品种、颜色、气味特征等等....我也不会惊讶，因为这是描述一个苹果的特征，也是机器定义这是一个苹果的依据。你看，这里就出现了一个人类与机器的差异，我们学习一个事物并不需要太多维度的特征来描述一个事物，比如，在某某地区生长的、重量在这个范围的、颜色可能是这种的、可能有这些形状的、...（此处省略无限字，因为可以从无限个维度去描述一个苹果）,OK,这个东西叫苹果！我们只要摸过吃过看过，大概就知道啥是苹果，也不会和梨搞错，为什么！因为我们聪明，没错，我们的大脑做了定义和判断的工作并且是在我们无意识的情况下。从这个角度上来说，其实研究机器学习的本质其实是研究人类自己认识这个世界的过程。  \n   \n\n<h2 id='id2'>神经网络</h2>\n  &emsp;&emsp;本篇文章的主题就是人工神经网络中的反向传播算法（Back Propagation Algorithm，BP算法）。反向传播算法是实现人工神经网络（Neural Networks，NNs）中非常重要的技术，就是它让神经网络变的“智能”，本文将会利用最简单的NNs模型来模拟整个反向传播算法，并同时使用JavaScript来实现整个过程，文章的最后会提供程序给大家交流，这里需要声明一点，这个程序只是为了演示算法。好了，开始吧。\n  &emsp;&emsp;首先神经网络的模型是这个样子的，这是一个简化到不能在简化的神经网络结构，图中的球模拟了神经元的细胞，线模拟了神经元的突触，简而言之它在用数学模型模拟我们的大脑：\n\n<center> <img src=\"/images/bp/bp1.svg\"> </center>\n\n  \n  &emsp;&emsp;在左侧有i1,i2，表示输入层；最右侧有o1,o2,表示输出层。当我们在训练机器学习的时候，会把输入值和输出值都设定好，好比说，i1=0.15，i2=0.10；计算结果应该是o1=0.01,o2=0.99，如果训练是成功的，那当我输入相同的输入值时，结果应该也是相同的。是不是有点像我们在构造一个函数，而这个函数的计算过程我们并不能看到，这也是为什么很多人说神经网络是一个黑盒模型。我们需要在中间加入一层来描述其中转换的过程，由于是不可见的，这层叫隐含层h1,h2。现在我们需要初始化节点之间的连线，为这些连线加上随机的权值。这些初始化的权值会在之后的计算中被更新，事实上这些权值就是描述这个机器思考的模型。在计算的过程中，我们还会用到b1,b2，这称为偏置项，值永远是1，权值可以自由设置，这里我们设b1权值为0.35，b2权值为0.60。OK,现在这个模型变成了这样：\n  \n<center> <img src=\"/images/bp/bp2.svg\"> </center>\n\n  &emsp;&emsp;好了，一切就绪，我们要开始算了！怎么算呢？整个算法的过程分为3个部分：前向传播、计算误差、反向传播，可以理解为我先试一下现在判断，与预期的判断做个比较，然后修正我的判断，下面就每个步骤详细说明一下。\n  \n<h3 id='id3'>前向传播</h3>\n\n  &emsp;&emsp;首先我们会从模型的左侧计算到右侧，这个方向称为前向。这一步可以分为2步，第1步是简单的加权相加或者叫做线性回归，第2步是代入一个激活函数，激活函数的作用是将线性函数表达为非线性函数，它会把值挤压进一个(0,1)区间的范围作为规范化处理，同时还可以反应出对象的条件概率，激活函数使用sigmoid函数,exp函数表示了以e为底的指数函数: \n\n<center> <img src=\"/images/bp/f1.gif\"> </center>\n    ```\n//激活函数\nthis.sigmoid=function(z) {\n\treturn 1 / (1 + Math.exp(-z));\n}\n    ```\n\n  &emsp;&emsp;第1步，计算线性回归：    \n<center> <img src=\"/images/bp/f2.gif\"> </center>  \n  &emsp;&emsp;第2步，激活：\n<center> <img src=\"/images/bp/f3.svg\"> </center>   \n  &emsp;&emsp;现在我们就计算出了h1节点的值，用相同的方法，我们计算出h2，o1，o2节点:\n<center>\n<img src=\"/images/bp/f4.gif\">\n<img src=\"/images/bp/f5.gif\">\n<img src=\"/images/bp/f6.gif\">\n</center>\n  ```\n  //前向传播\n  this.forward=function() {\n    //隐含层\n    for (var x = 0; x < i.length; x++) {\n      h[x] = sigmoid(i[0] * w[0][x * v] + i[1] * w[0][x * v + 1] + b[0]);\n    }\n    //输出层\n    for (var y = 0; y < i.length; y++) {\n      o[y] = sigmoid(h[0] * w[1][y * v] + h[1] * w[1][y * v + 1] + b[1]);\n    }\n  }\n  ```\n  &emsp;&emsp;可以看到计算的结果和我们设定的结果(0.01,0.99)有很大的误差，这很大程度上是由于权值初始化的时候，接下来我们需要减小这个误差。  \n<h3 id='id4'>计算总误差</h3>\n  &emsp;&emsp;误差计算通过平方误差函数为每个节点计算误差，然后将这些误差相加计算总误差:\n  \n<center><img src=\"/images/bp/f7.gif\"></center>\n    ```\n    //计算总误差\n    this.totalError=function() {\n      for (var x = 0; x < t.length; x++) {\n        e[x] = squareErr(t[x], o[x]);\n        te += e[x];\n      }\n    }\n    ```\n  &emsp;&emsp;我们分别计算o1，o2的误差值，并将他们相加:\n\n<center>\n<img src=\"/images/bp/f8.gif\">\n<img src=\"/images/bp/f9.gif\">\n<img src=\"/images/bp/f10.gif\">\n</center>\n<h3 id='id5'>反向传播</h3>\n  &emsp;&emsp;现在我们从模型的右侧开始向左侧计算，目标是要使得总误差值变小。我们首先计算w5这一路，这里需要一个方法来计算w5对总误差的影响，刚好导数的意义是描述参数变化对函数造成影响的变化率，或者叫斜率。所以我们想知道w5对总误差带来的变化率可以通过求w5的偏导来计算。然而单纯去算是算不出的，要使用连式法则来分解计算步骤（宏观上看这些中间变量都可以被约分约掉）,下面我们就将这个问题分为等式右侧的3部分去求解：\n<center>\n<img src=\"/images/bp/f11.gif\">\n</center>\n  &emsp;&emsp;第1部分，o1的输出对于总误差的影响，由于我们不关心o2的输出，所以整个右侧可以计算为0，然后利用求导公式就可以算出：\n<center>\n<img src=\"/images/bp/f12.gif\">\n</center>\n  &emsp;&emsp;代入之前的数据可以求解：\n<center>\n<img src=\"/images/bp/f13.gif\">\n</center>\n &emsp;&emsp;第2部分，这里其实就是对于激活函数来说，o1输出对它的影响，由于激活函数是sigmoid，其求导公式推导如下：\n<center>\n<img src=\"/images/bp/f14.gif\">\n</center>\n  &emsp;&emsp;所以我们可以得到第二部分的求解：\n<center>\n<img src=\"/images/bp/f15.gif\">\n</center>\n  &emsp;&emsp;第3部分，w5对于线性方程的影响，其求导结果就是w5的斜率：\n<center>\n<img src=\"/images/bp/f16.gif\">\n</center>\n  &emsp;&emsp;现在！该有的都有了，现在我们知道w5对于总误差的影响有多大了：\n<center>\n<img src=\"/images/bp/f17.gif\">\n</center>\n  &emsp;&emsp;我们现在要对w5这项权值做出调整，调整的依据是刚刚算出的误差值，通过加权的方式去调整，我们需要设定一个学习率来衡量误差对于调整过程的比例，本例中设为0.5：\n<center>\n<img src=\"/images/bp/f18.gif\">\n</center>  \n  &emsp;&emsp;神奇的事情发生了，可以看到w5的权值由原来的0.3调整为0.25772292463736585，从调整的幅度上来看好像还挺有道理的，我们用相同的方法把所有的权值都调整一遍：\n\n``` \n//反向传播第一层\nthis.backward1 =function() {\t\n\tfor (var y = 0; y < t.length; y++) {\n\t\tfor (var x = 0; x < h.length; x++) {\n\t\t\tvar selfEffect = -1 * (t[y] - o[y]) * o[y] * (1 - o[y]) * h[x];\n\t\t\tnW[1][x + y * v] = w[1][x + y * v] - lr * selfEffect;\n\t\t\tconsole.info('w' + parseInt(5 + x + y * v) + \"权重变化: \" + w[1][x + y * v] + \" => \" + nW[1][x + y * v]);\n\t\t}\n\t}\n}\n---------------\nw5权重变化: 0.3 => 0.25772292463736585\nw6权重变化: 0.35 => 0.3075091952101869\nw7权重变化: 0.4 => 0.413242963882813\nw8权重变化: 0.45 => 0.46330991295770874\n```\n\n  &emsp;&emsp;OK,到目前为止，我们已经成功一半了，接下来需要更新w1~w4的权值，以w1为例，我们需要算出w1对于总误差的影响，依然通过链式法则求偏导：\n<center>\n<img src=\"/images/bp/f19.gif\">\n</center>  \n  &emsp;&emsp;这里有一个情况出现了，我们的算式里第一项是描述h1节点对于总误差的影响，如何描述这个影响，直接求求不出啊？冷静，思路依然是将问题细分，我们可以看到模型中这个h1节点可以影响o1,也可以影响o2，所以这个过程可以看做h1对o1,o2的影响之和，下面我们开始计算：\n<center>\n<img src=\"/images/bp/f20.gif\">\n</center>\n  &emsp;&emsp;第1部分，这一部分其实又可以分为2个小部分，我们以计算o1例。在计算的时候有一个技巧，o1输出对于E0的影响其实就等于o1输出对于E_total的影响，所以可以用之前算过的值直接代入；由于out_o1是线性方程，h1对于out_o1的影响就等于其斜率w5：\n<center>\n\n<img src=\"/images/bp/f21.gif\">\n<img src=\"/images/bp/f22.gif\">\n</center>\n  &emsp;&emsp;代入之前求得的值就可以求解第1部分：\n<center>\n<img src=\"/images/bp/f23.gif\">\n<img src=\"/images/bp/f24.gif\">\n<img src=\"/images/bp/f25.gif\">\n</center>\n  &emsp;&emsp;第2部分，就是对sigmoid函数求导，代入可以求解：\n<center>\n<img src=\"/images/bp/f26.gif\">\n</center>\n  &emsp;&emsp;第3部分，是对线性函数求导，求解：\n<center>\n<img src=\"/images/bp/f27.gif\">\n</center>\n  &emsp;&emsp;大功告成，我们将3部分数据相乘，并加上学习率，最终求解：\n<center>\n<img src=\"/images/bp/f28.gif\">\n<img src=\"/images/bp/f29.gif\">\n</center>\n  &emsp;&emsp;我们将其余的权重都求解：\n```\n//反向传播第二层\nthis.backward2 = function() {\n\tvar f_1 = [];\n\tvar f_2 = 0;\n\tvar f_3 = 0;\n\tvar _f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][0];\n\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][2];\n\tf_1.push(_f_1);\n\t_f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][1];\n\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][3];\n\tf_1.push(_f_1);\n\tfor (var y = 0; y < h.length; y++) {\n\t\tf_2 = h[y] * (1 - h[y]);\n\t\tfor (var z = 0; z < i.length; z++) {\n\t\t\tf_3 = i[z];\n\t\t\tnW[0][y + z * v] = w[0][y + z * v] - lr * (f_1[y] * f_2 * f_3);\n\t\t\tconsole.info('w' + parseInt(y + z * v) + \"权重变化: \" + w[1][y + z * v] + \" => \" + nW[1][y + z * v]);\n\t\t}\n\t}\n\tw = nW;\n};\n--------------------\nw0权重变化: 0.3 => 0.25772292463736585\nw2权重变化: 0.4 => 0.413242963882813\nw1权重变化: 0.35 => 0.3075091952101869\nw3权重变化: 0.45 => 0.46330991295770874\n```\n\n\n\n &emsp;&emsp;目前为止，我们已经完成了训练，接下来我们来验证一下训练的成果。仍然将[0.15,0.1]作为输入层输入，我们看到通过新的权重计算后得到的结果是:\n```\n预测值变化：0.7286638276265998,0.751601224586807 => 0.7185477013468267,0.7545430129300831\n```\n &emsp;&emsp;可以观察到o1越来越接近0.01,o2越来越接近0.99，OK，我们来循环10000次，观察训练后的结果：\n```\nvar test = new Neural();\nvar final_o=[];\nfor (var i = 0; i < 10000; i++) {\n\ttest.forward();\n\tvar old_o=[].concat(test.o);\n\ttest.totalError();\n\ttest.backward1();\n\ttest.backward2();\n\ttest.forward();\n\tfinal_o=[].concat(test.o);\t\n}\nconsole.info('最终预测值：'+final_o);\n-----------------------\n最终预测值：0.015360963767399535,0.9845412722122693\n```\n  &emsp;&emsp;成功！\n\n<h3 id='id6'>结语</h3>\n  &emsp;&emsp;我们已经模拟了最为简单的情况，可以想像如果增加输入层维度，并且增加隐含层层数，模型的拟合度会越来越高，但计算量也会指数倍增长。\n<!-- out_h1=0.595078473866134-->\n<!-- out_o1=0.7286638276265998-->\n<!--$$n_{h1}=i_1 * w_1 + i_2 * w_2 + b_1 * 1=0.15 * 0.1 + 0.1 * 0.2 + 0.35 * 1=0.385$$-->\n<!--$$out_{h1}=\\frac {1} {1+exp^{(-n_h1)}}=\\frac {1} {1+exp^{(-0.385)}}=0.595078473866134$$-->\n<!--$$E_{o1}=\\frac 1 2(o1 - out_{o1} )^2= \\frac 1 2(0.01 - 0.7286638276265998)^2=0.25823884856945756 $$-->\n<!--$$E_{o2}=\\frac 1 2(o2 - out_{o2} )^2= \\frac 1 2(0.99 - 0.751601224586807)^2=0.028416988059255015 $$-->\n<!--$$E_{total}=(E_{o1} + E_{o2})=(0.25823884856945756+0.028416988059255015)=0.2866558366287126 $$-->\n<!--\\frac {\\partial E_{total}} {\\partial w_{5}} =\\frac {\\partial E_{total}} {\\partial out_{o1}} * \\frac {\\partial out_{o1}} {\\partial n_{1}} *{\\partial n_{1}} {\\partial w_{5}} -->\n<!--\\frac {\\partial E_{total}} {\\partial out_{o1}} =\\frac {\\partial (\\frac 1 2(o_1 - out_{o1} )^2 + \\frac 1 2(o_2 - out_{o2} )^2) } {\\partial out_{o1}}=2 * \\frac 1 2 (o_1 - out_{o1})^{2-1} * -1 + 0-->\n<!--\\frac {\\partial out_{o1}} {\\partial n_{o1}} =\\frac {\\partial (\\frac {1} {1+exp^{(-n_o1)}})} {\\partial n_{o1}} = -->\n<!--f(x)'={(\\frac 1 {1+exp^{-x}})}'={(\\frac {exp^x} {1+exp^{x}})}'=\\frac {exp^x}{(exp^x + 1)^2}=f(x)*(1-f(x))-->\n<!--\\frac {\\partial E_{total}} {\\partial w_{1}} = ( \\frac {\\partial E_{o1}} {\\partial out_{h1}} + \\frac {\\partial E_{o2}} {\\partial out_{h1}})*\\frac {\\partial out_{h1}} {\\partial n_{h1}} *\\frac {\\partial n_{h1}} {\\partial w_{1}} -->\n<!--\\frac {\\partial E_{o1}} {\\partial out_{h1}} =\\frac {\\partial E_{o1}} {\\partial n_{h1}} * \\frac {\\partial n_{h1}} {\\partial out_{h1}} = \\frac {\\partial E_{total}} {\\partial out_{o1}} * \\frac {\\partial out_{o1}} {\\partial n_{h1}}* \\frac {\\partial n_{h1}} {\\partial out_{h1}}-->\n<!--\\frac {\\partial E_{o2}} {\\partial out_{h1}} =0.7186638276265997 * 0.19771285393515267 * 0.3=0.0426267229140047 -->\n---","source":"_posts/bp.md","raw":"---\ntitle: 超酷的反向传播算法\ntags:\n  - 神经网络\n  - 机器学习\ncategories: \n  - Tech\n---\n<h2 id='id1' >人工智能</h2>\n  &emsp;&emsp;目前最火的技术莫过于人工智能，或者说机器学习。从IBM Watson到Google AlphaGo,人工智能仿佛已经冲出了实验室，在实际生活中发挥作用。面对如此高大上的技术，普通老百姓要如何去看待它，理解它的本质呢?沉着冷静别惊慌，本文将尽可能给你一个答案。\n  \n  &emsp;&emsp;首先要知道机器学习的本质是算法，这里就会有好几种，比如：神经网络、支持向量机、朴素贝叶斯等等一堆。虽然算法很多，但他们主要解决的都是同一个问题---分类预测问题。为什么分类预测问题这么重要？因为机器学习的本质是重现人类学习的过程，这个过程可以大致分为两部分：1.定义一个事物，2.判断一个事物。如果一个机器可以对一个事物进行判断，判断的结果与人类的判断相似，那它近似的就是一个人工智能。\n\n  &emsp;&emsp;假设这样一个场景，我和机器都看到了一个苹果，按照之前对机器的训练如果他告诉我他看到了一个苹果，那说明这个机器是具有一定人工智能的，如果它还能告诉我这个苹果的产地，成熟度，净重，品种、颜色、气味特征等等....我也不会惊讶，因为这是描述一个苹果的特征，也是机器定义这是一个苹果的依据。你看，这里就出现了一个人类与机器的差异，我们学习一个事物并不需要太多维度的特征来描述一个事物，比如，在某某地区生长的、重量在这个范围的、颜色可能是这种的、可能有这些形状的、...（此处省略无限字，因为可以从无限个维度去描述一个苹果）,OK,这个东西叫苹果！我们只要摸过吃过看过，大概就知道啥是苹果，也不会和梨搞错，为什么！因为我们聪明，没错，我们的大脑做了定义和判断的工作并且是在我们无意识的情况下。从这个角度上来说，其实研究机器学习的本质其实是研究人类自己认识这个世界的过程。  \n   \n\n<h2 id='id2'>神经网络</h2>\n  &emsp;&emsp;本篇文章的主题就是人工神经网络中的反向传播算法（Back Propagation Algorithm，BP算法）。反向传播算法是实现人工神经网络（Neural Networks，NNs）中非常重要的技术，就是它让神经网络变的“智能”，本文将会利用最简单的NNs模型来模拟整个反向传播算法，并同时使用JavaScript来实现整个过程，文章的最后会提供程序给大家交流，这里需要声明一点，这个程序只是为了演示算法。好了，开始吧。\n  &emsp;&emsp;首先神经网络的模型是这个样子的，这是一个简化到不能在简化的神经网络结构，图中的球模拟了神经元的细胞，线模拟了神经元的突触，简而言之它在用数学模型模拟我们的大脑：\n\n<center> <img src=\"/images/bp/bp1.svg\"> </center>\n\n  \n  &emsp;&emsp;在左侧有i1,i2，表示输入层；最右侧有o1,o2,表示输出层。当我们在训练机器学习的时候，会把输入值和输出值都设定好，好比说，i1=0.15，i2=0.10；计算结果应该是o1=0.01,o2=0.99，如果训练是成功的，那当我输入相同的输入值时，结果应该也是相同的。是不是有点像我们在构造一个函数，而这个函数的计算过程我们并不能看到，这也是为什么很多人说神经网络是一个黑盒模型。我们需要在中间加入一层来描述其中转换的过程，由于是不可见的，这层叫隐含层h1,h2。现在我们需要初始化节点之间的连线，为这些连线加上随机的权值。这些初始化的权值会在之后的计算中被更新，事实上这些权值就是描述这个机器思考的模型。在计算的过程中，我们还会用到b1,b2，这称为偏置项，值永远是1，权值可以自由设置，这里我们设b1权值为0.35，b2权值为0.60。OK,现在这个模型变成了这样：\n  \n<center> <img src=\"/images/bp/bp2.svg\"> </center>\n\n  &emsp;&emsp;好了，一切就绪，我们要开始算了！怎么算呢？整个算法的过程分为3个部分：前向传播、计算误差、反向传播，可以理解为我先试一下现在判断，与预期的判断做个比较，然后修正我的判断，下面就每个步骤详细说明一下。\n  \n<h3 id='id3'>前向传播</h3>\n\n  &emsp;&emsp;首先我们会从模型的左侧计算到右侧，这个方向称为前向。这一步可以分为2步，第1步是简单的加权相加或者叫做线性回归，第2步是代入一个激活函数，激活函数的作用是将线性函数表达为非线性函数，它会把值挤压进一个(0,1)区间的范围作为规范化处理，同时还可以反应出对象的条件概率，激活函数使用sigmoid函数,exp函数表示了以e为底的指数函数: \n\n<center> <img src=\"/images/bp/f1.gif\"> </center>\n    ```\n//激活函数\nthis.sigmoid=function(z) {\n\treturn 1 / (1 + Math.exp(-z));\n}\n    ```\n\n  &emsp;&emsp;第1步，计算线性回归：    \n<center> <img src=\"/images/bp/f2.gif\"> </center>  \n  &emsp;&emsp;第2步，激活：\n<center> <img src=\"/images/bp/f3.svg\"> </center>   \n  &emsp;&emsp;现在我们就计算出了h1节点的值，用相同的方法，我们计算出h2，o1，o2节点:\n<center>\n<img src=\"/images/bp/f4.gif\">\n<img src=\"/images/bp/f5.gif\">\n<img src=\"/images/bp/f6.gif\">\n</center>\n  ```\n  //前向传播\n  this.forward=function() {\n    //隐含层\n    for (var x = 0; x < i.length; x++) {\n      h[x] = sigmoid(i[0] * w[0][x * v] + i[1] * w[0][x * v + 1] + b[0]);\n    }\n    //输出层\n    for (var y = 0; y < i.length; y++) {\n      o[y] = sigmoid(h[0] * w[1][y * v] + h[1] * w[1][y * v + 1] + b[1]);\n    }\n  }\n  ```\n  &emsp;&emsp;可以看到计算的结果和我们设定的结果(0.01,0.99)有很大的误差，这很大程度上是由于权值初始化的时候，接下来我们需要减小这个误差。  \n<h3 id='id4'>计算总误差</h3>\n  &emsp;&emsp;误差计算通过平方误差函数为每个节点计算误差，然后将这些误差相加计算总误差:\n  \n<center><img src=\"/images/bp/f7.gif\"></center>\n    ```\n    //计算总误差\n    this.totalError=function() {\n      for (var x = 0; x < t.length; x++) {\n        e[x] = squareErr(t[x], o[x]);\n        te += e[x];\n      }\n    }\n    ```\n  &emsp;&emsp;我们分别计算o1，o2的误差值，并将他们相加:\n\n<center>\n<img src=\"/images/bp/f8.gif\">\n<img src=\"/images/bp/f9.gif\">\n<img src=\"/images/bp/f10.gif\">\n</center>\n<h3 id='id5'>反向传播</h3>\n  &emsp;&emsp;现在我们从模型的右侧开始向左侧计算，目标是要使得总误差值变小。我们首先计算w5这一路，这里需要一个方法来计算w5对总误差的影响，刚好导数的意义是描述参数变化对函数造成影响的变化率，或者叫斜率。所以我们想知道w5对总误差带来的变化率可以通过求w5的偏导来计算。然而单纯去算是算不出的，要使用连式法则来分解计算步骤（宏观上看这些中间变量都可以被约分约掉）,下面我们就将这个问题分为等式右侧的3部分去求解：\n<center>\n<img src=\"/images/bp/f11.gif\">\n</center>\n  &emsp;&emsp;第1部分，o1的输出对于总误差的影响，由于我们不关心o2的输出，所以整个右侧可以计算为0，然后利用求导公式就可以算出：\n<center>\n<img src=\"/images/bp/f12.gif\">\n</center>\n  &emsp;&emsp;代入之前的数据可以求解：\n<center>\n<img src=\"/images/bp/f13.gif\">\n</center>\n &emsp;&emsp;第2部分，这里其实就是对于激活函数来说，o1输出对它的影响，由于激活函数是sigmoid，其求导公式推导如下：\n<center>\n<img src=\"/images/bp/f14.gif\">\n</center>\n  &emsp;&emsp;所以我们可以得到第二部分的求解：\n<center>\n<img src=\"/images/bp/f15.gif\">\n</center>\n  &emsp;&emsp;第3部分，w5对于线性方程的影响，其求导结果就是w5的斜率：\n<center>\n<img src=\"/images/bp/f16.gif\">\n</center>\n  &emsp;&emsp;现在！该有的都有了，现在我们知道w5对于总误差的影响有多大了：\n<center>\n<img src=\"/images/bp/f17.gif\">\n</center>\n  &emsp;&emsp;我们现在要对w5这项权值做出调整，调整的依据是刚刚算出的误差值，通过加权的方式去调整，我们需要设定一个学习率来衡量误差对于调整过程的比例，本例中设为0.5：\n<center>\n<img src=\"/images/bp/f18.gif\">\n</center>  \n  &emsp;&emsp;神奇的事情发生了，可以看到w5的权值由原来的0.3调整为0.25772292463736585，从调整的幅度上来看好像还挺有道理的，我们用相同的方法把所有的权值都调整一遍：\n\n``` \n//反向传播第一层\nthis.backward1 =function() {\t\n\tfor (var y = 0; y < t.length; y++) {\n\t\tfor (var x = 0; x < h.length; x++) {\n\t\t\tvar selfEffect = -1 * (t[y] - o[y]) * o[y] * (1 - o[y]) * h[x];\n\t\t\tnW[1][x + y * v] = w[1][x + y * v] - lr * selfEffect;\n\t\t\tconsole.info('w' + parseInt(5 + x + y * v) + \"权重变化: \" + w[1][x + y * v] + \" => \" + nW[1][x + y * v]);\n\t\t}\n\t}\n}\n---------------\nw5权重变化: 0.3 => 0.25772292463736585\nw6权重变化: 0.35 => 0.3075091952101869\nw7权重变化: 0.4 => 0.413242963882813\nw8权重变化: 0.45 => 0.46330991295770874\n```\n\n  &emsp;&emsp;OK,到目前为止，我们已经成功一半了，接下来需要更新w1~w4的权值，以w1为例，我们需要算出w1对于总误差的影响，依然通过链式法则求偏导：\n<center>\n<img src=\"/images/bp/f19.gif\">\n</center>  \n  &emsp;&emsp;这里有一个情况出现了，我们的算式里第一项是描述h1节点对于总误差的影响，如何描述这个影响，直接求求不出啊？冷静，思路依然是将问题细分，我们可以看到模型中这个h1节点可以影响o1,也可以影响o2，所以这个过程可以看做h1对o1,o2的影响之和，下面我们开始计算：\n<center>\n<img src=\"/images/bp/f20.gif\">\n</center>\n  &emsp;&emsp;第1部分，这一部分其实又可以分为2个小部分，我们以计算o1例。在计算的时候有一个技巧，o1输出对于E0的影响其实就等于o1输出对于E_total的影响，所以可以用之前算过的值直接代入；由于out_o1是线性方程，h1对于out_o1的影响就等于其斜率w5：\n<center>\n\n<img src=\"/images/bp/f21.gif\">\n<img src=\"/images/bp/f22.gif\">\n</center>\n  &emsp;&emsp;代入之前求得的值就可以求解第1部分：\n<center>\n<img src=\"/images/bp/f23.gif\">\n<img src=\"/images/bp/f24.gif\">\n<img src=\"/images/bp/f25.gif\">\n</center>\n  &emsp;&emsp;第2部分，就是对sigmoid函数求导，代入可以求解：\n<center>\n<img src=\"/images/bp/f26.gif\">\n</center>\n  &emsp;&emsp;第3部分，是对线性函数求导，求解：\n<center>\n<img src=\"/images/bp/f27.gif\">\n</center>\n  &emsp;&emsp;大功告成，我们将3部分数据相乘，并加上学习率，最终求解：\n<center>\n<img src=\"/images/bp/f28.gif\">\n<img src=\"/images/bp/f29.gif\">\n</center>\n  &emsp;&emsp;我们将其余的权重都求解：\n```\n//反向传播第二层\nthis.backward2 = function() {\n\tvar f_1 = [];\n\tvar f_2 = 0;\n\tvar f_3 = 0;\n\tvar _f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][0];\n\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][2];\n\tf_1.push(_f_1);\n\t_f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][1];\n\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][3];\n\tf_1.push(_f_1);\n\tfor (var y = 0; y < h.length; y++) {\n\t\tf_2 = h[y] * (1 - h[y]);\n\t\tfor (var z = 0; z < i.length; z++) {\n\t\t\tf_3 = i[z];\n\t\t\tnW[0][y + z * v] = w[0][y + z * v] - lr * (f_1[y] * f_2 * f_3);\n\t\t\tconsole.info('w' + parseInt(y + z * v) + \"权重变化: \" + w[1][y + z * v] + \" => \" + nW[1][y + z * v]);\n\t\t}\n\t}\n\tw = nW;\n};\n--------------------\nw0权重变化: 0.3 => 0.25772292463736585\nw2权重变化: 0.4 => 0.413242963882813\nw1权重变化: 0.35 => 0.3075091952101869\nw3权重变化: 0.45 => 0.46330991295770874\n```\n\n\n\n &emsp;&emsp;目前为止，我们已经完成了训练，接下来我们来验证一下训练的成果。仍然将[0.15,0.1]作为输入层输入，我们看到通过新的权重计算后得到的结果是:\n```\n预测值变化：0.7286638276265998,0.751601224586807 => 0.7185477013468267,0.7545430129300831\n```\n &emsp;&emsp;可以观察到o1越来越接近0.01,o2越来越接近0.99，OK，我们来循环10000次，观察训练后的结果：\n```\nvar test = new Neural();\nvar final_o=[];\nfor (var i = 0; i < 10000; i++) {\n\ttest.forward();\n\tvar old_o=[].concat(test.o);\n\ttest.totalError();\n\ttest.backward1();\n\ttest.backward2();\n\ttest.forward();\n\tfinal_o=[].concat(test.o);\t\n}\nconsole.info('最终预测值：'+final_o);\n-----------------------\n最终预测值：0.015360963767399535,0.9845412722122693\n```\n  &emsp;&emsp;成功！\n\n<h3 id='id6'>结语</h3>\n  &emsp;&emsp;我们已经模拟了最为简单的情况，可以想像如果增加输入层维度，并且增加隐含层层数，模型的拟合度会越来越高，但计算量也会指数倍增长。\n<!-- out_h1=0.595078473866134-->\n<!-- out_o1=0.7286638276265998-->\n<!--$$n_{h1}=i_1 * w_1 + i_2 * w_2 + b_1 * 1=0.15 * 0.1 + 0.1 * 0.2 + 0.35 * 1=0.385$$-->\n<!--$$out_{h1}=\\frac {1} {1+exp^{(-n_h1)}}=\\frac {1} {1+exp^{(-0.385)}}=0.595078473866134$$-->\n<!--$$E_{o1}=\\frac 1 2(o1 - out_{o1} )^2= \\frac 1 2(0.01 - 0.7286638276265998)^2=0.25823884856945756 $$-->\n<!--$$E_{o2}=\\frac 1 2(o2 - out_{o2} )^2= \\frac 1 2(0.99 - 0.751601224586807)^2=0.028416988059255015 $$-->\n<!--$$E_{total}=(E_{o1} + E_{o2})=(0.25823884856945756+0.028416988059255015)=0.2866558366287126 $$-->\n<!--\\frac {\\partial E_{total}} {\\partial w_{5}} =\\frac {\\partial E_{total}} {\\partial out_{o1}} * \\frac {\\partial out_{o1}} {\\partial n_{1}} *{\\partial n_{1}} {\\partial w_{5}} -->\n<!--\\frac {\\partial E_{total}} {\\partial out_{o1}} =\\frac {\\partial (\\frac 1 2(o_1 - out_{o1} )^2 + \\frac 1 2(o_2 - out_{o2} )^2) } {\\partial out_{o1}}=2 * \\frac 1 2 (o_1 - out_{o1})^{2-1} * -1 + 0-->\n<!--\\frac {\\partial out_{o1}} {\\partial n_{o1}} =\\frac {\\partial (\\frac {1} {1+exp^{(-n_o1)}})} {\\partial n_{o1}} = -->\n<!--f(x)'={(\\frac 1 {1+exp^{-x}})}'={(\\frac {exp^x} {1+exp^{x}})}'=\\frac {exp^x}{(exp^x + 1)^2}=f(x)*(1-f(x))-->\n<!--\\frac {\\partial E_{total}} {\\partial w_{1}} = ( \\frac {\\partial E_{o1}} {\\partial out_{h1}} + \\frac {\\partial E_{o2}} {\\partial out_{h1}})*\\frac {\\partial out_{h1}} {\\partial n_{h1}} *\\frac {\\partial n_{h1}} {\\partial w_{1}} -->\n<!--\\frac {\\partial E_{o1}} {\\partial out_{h1}} =\\frac {\\partial E_{o1}} {\\partial n_{h1}} * \\frac {\\partial n_{h1}} {\\partial out_{h1}} = \\frac {\\partial E_{total}} {\\partial out_{o1}} * \\frac {\\partial out_{o1}} {\\partial n_{h1}}* \\frac {\\partial n_{h1}} {\\partial out_{h1}}-->\n<!--\\frac {\\partial E_{o2}} {\\partial out_{h1}} =0.7186638276265997 * 0.19771285393515267 * 0.3=0.0426267229140047 -->\n---","slug":"bp","published":1,"date":"2017-03-29T01:52:53.963Z","updated":"2017-03-29T01:52:53.963Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj0ubhjxx00007u8g3lklsgbe","content":"<p></p><h2 id=\"id1\">人工智能</h2><br>  &emsp;&emsp;目前最火的技术莫过于人工智能，或者说机器学习。从IBM Watson到Google AlphaGo,人工智能仿佛已经冲出了实验室，在实际生活中发挥作用。面对如此高大上的技术，普通老百姓要如何去看待它，理解它的本质呢?沉着冷静别惊慌，本文将尽可能给你一个答案。<p></p>\n<p>  &emsp;&emsp;首先要知道机器学习的本质是算法，这里就会有好几种，比如：神经网络、支持向量机、朴素贝叶斯等等一堆。虽然算法很多，但他们主要解决的都是同一个问题—分类预测问题。为什么分类预测问题这么重要？因为机器学习的本质是重现人类学习的过程，这个过程可以大致分为两部分：1.定义一个事物，2.判断一个事物。如果一个机器可以对一个事物进行判断，判断的结果与人类的判断相似，那它近似的就是一个人工智能。</p>\n<p>  &emsp;&emsp;假设这样一个场景，我和机器都看到了一个苹果，按照之前对机器的训练如果他告诉我他看到了一个苹果，那说明这个机器是具有一定人工智能的，如果它还能告诉我这个苹果的产地，成熟度，净重，品种、颜色、气味特征等等….我也不会惊讶，因为这是描述一个苹果的特征，也是机器定义这是一个苹果的依据。你看，这里就出现了一个人类与机器的差异，我们学习一个事物并不需要太多维度的特征来描述一个事物，比如，在某某地区生长的、重量在这个范围的、颜色可能是这种的、可能有这些形状的、…（此处省略无限字，因为可以从无限个维度去描述一个苹果）,OK,这个东西叫苹果！我们只要摸过吃过看过，大概就知道啥是苹果，也不会和梨搞错，为什么！因为我们聪明，没错，我们的大脑做了定义和判断的工作并且是在我们无意识的情况下。从这个角度上来说，其实研究机器学习的本质其实是研究人类自己认识这个世界的过程。  </p>\n<p></p><h2 id=\"id2\">神经网络</h2><br>  &emsp;&emsp;本篇文章的主题就是人工神经网络中的反向传播算法（Back Propagation Algorithm，BP算法）。反向传播算法是实现人工神经网络（Neural Networks，NNs）中非常重要的技术，就是它让神经网络变的“智能”，本文将会利用最简单的NNs模型来模拟整个反向传播算法，并同时使用JavaScript来实现整个过程，文章的最后会提供程序给大家交流，这里需要声明一点，这个程序只是为了演示算法。好了，开始吧。<br>  &emsp;&emsp;首先神经网络的模型是这个样子的，这是一个简化到不能在简化的神经网络结构，图中的球模拟了神经元的细胞，线模拟了神经元的突触，简而言之它在用数学模型模拟我们的大脑：<p></p>\n<center> <img src=\"/images/bp/bp1.svg\"> </center>\n\n\n<p>  &emsp;&emsp;在左侧有i1,i2，表示输入层；最右侧有o1,o2,表示输出层。当我们在训练机器学习的时候，会把输入值和输出值都设定好，好比说，i1=0.15，i2=0.10；计算结果应该是o1=0.01,o2=0.99，如果训练是成功的，那当我输入相同的输入值时，结果应该也是相同的。是不是有点像我们在构造一个函数，而这个函数的计算过程我们并不能看到，这也是为什么很多人说神经网络是一个黑盒模型。我们需要在中间加入一层来描述其中转换的过程，由于是不可见的，这层叫隐含层h1,h2。现在我们需要初始化节点之间的连线，为这些连线加上随机的权值。这些初始化的权值会在之后的计算中被更新，事实上这些权值就是描述这个机器思考的模型。在计算的过程中，我们还会用到b1,b2，这称为偏置项，值永远是1，权值可以自由设置，这里我们设b1权值为0.35，b2权值为0.60。OK,现在这个模型变成了这样：</p>\n<center> <img src=\"/images/bp/bp2.svg\"> </center>\n\n<p>  &emsp;&emsp;好了，一切就绪，我们要开始算了！怎么算呢？整个算法的过程分为3个部分：前向传播、计算误差、反向传播，可以理解为我先试一下现在判断，与预期的判断做个比较，然后修正我的判断，下面就每个步骤详细说明一下。</p>\n<h3 id=\"id3\">前向传播</h3>\n\n<p>  &emsp;&emsp;首先我们会从模型的左侧计算到右侧，这个方向称为前向。这一步可以分为2步，第1步是简单的加权相加或者叫做线性回归，第2步是代入一个激活函数，激活函数的作用是将线性函数表达为非线性函数，它会把值挤压进一个(0,1)区间的范围作为规范化处理，同时还可以反应出对象的条件概率，激活函数使用sigmoid函数,exp函数表示了以e为底的指数函数: </p>\n<p><center> <img src=\"/images/bp/f1.gif\"> </center><br>    <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">//激活函数</div><div class=\"line\">this.sigmoid=function(z) &#123;</div><div class=\"line\">\treturn 1 / (1 + Math.exp(-z));</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>  &emsp;&emsp;第1步，计算线性回归：    </p>\n<p><center> <img src=\"/images/bp/f2.gif\"> </center><br>  &emsp;&emsp;第2步，激活：</p>\n<p><center> <img src=\"/images/bp/f3.svg\"> </center><br>  &emsp;&emsp;现在我们就计算出了h1节点的值，用相同的方法，我们计算出h2，o1，o2节点:</p>\n<p><center><br><img src=\"/images/bp/f4.gif\"><br><img src=\"/images/bp/f5.gif\"><br><img src=\"/images/bp/f6.gif\"><br></center><br>  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">//前向传播</div><div class=\"line\">this.forward=function() &#123;</div><div class=\"line\">  //隐含层</div><div class=\"line\">  for (var x = 0; x &lt; i.length; x++) &#123;</div><div class=\"line\">    h[x] = sigmoid(i[0] * w[0][x * v] + i[1] * w[0][x * v + 1] + b[0]);</div><div class=\"line\">  &#125;</div><div class=\"line\">  //输出层</div><div class=\"line\">  for (var y = 0; y &lt; i.length; y++) &#123;</div><div class=\"line\">    o[y] = sigmoid(h[0] * w[1][y * v] + h[1] * w[1][y * v + 1] + b[1]);</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>  &emsp;&emsp;可以看到计算的结果和我们设定的结果(0.01,0.99)有很大的误差，这很大程度上是由于权值初始化的时候，接下来我们需要减小这个误差。  </p>\n<p></p><h3 id=\"id4\">计算总误差</h3><br>  &emsp;&emsp;误差计算通过平方误差函数为每个节点计算误差，然后将这些误差相加计算总误差:<p></p>\n<p><center><img src=\"/images/bp/f7.gif\"></center><br>    <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">//计算总误差</div><div class=\"line\">this.totalError=function() &#123;</div><div class=\"line\">  for (var x = 0; x &lt; t.length; x++) &#123;</div><div class=\"line\">    e[x] = squareErr(t[x], o[x]);</div><div class=\"line\">    te += e[x];</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>  &emsp;&emsp;我们分别计算o1，o2的误差值，并将他们相加:</p>\n<p><center><br><img src=\"/images/bp/f8.gif\"><br><img src=\"/images/bp/f9.gif\"><br><img src=\"/images/bp/f10.gif\"><br></center></p>\n<p></p><h3 id=\"id5\">反向传播</h3><br>  &emsp;&emsp;现在我们从模型的右侧开始向左侧计算，目标是要使得总误差值变小。我们首先计算w5这一路，这里需要一个方法来计算w5对总误差的影响，刚好导数的意义是描述参数变化对函数造成影响的变化率，或者叫斜率。所以我们想知道w5对总误差带来的变化率可以通过求w5的偏导来计算。然而单纯去算是算不出的，要使用连式法则来分解计算步骤（宏观上看这些中间变量都可以被约分约掉）,下面我们就将这个问题分为等式右侧的3部分去求解：<p></p>\n<p><center><br><img src=\"/images/bp/f11.gif\"><br></center><br>  &emsp;&emsp;第1部分，o1的输出对于总误差的影响，由于我们不关心o2的输出，所以整个右侧可以计算为0，然后利用求导公式就可以算出：</p>\n<p><center><br><img src=\"/images/bp/f12.gif\"><br></center><br>  &emsp;&emsp;代入之前的数据可以求解：</p>\n<p><center><br><img src=\"/images/bp/f13.gif\"><br></center><br> &emsp;&emsp;第2部分，这里其实就是对于激活函数来说，o1输出对它的影响，由于激活函数是sigmoid，其求导公式推导如下：</p>\n<p><center><br><img src=\"/images/bp/f14.gif\"><br></center><br>  &emsp;&emsp;所以我们可以得到第二部分的求解：</p>\n<p><center><br><img src=\"/images/bp/f15.gif\"><br></center><br>  &emsp;&emsp;第3部分，w5对于线性方程的影响，其求导结果就是w5的斜率：</p>\n<p><center><br><img src=\"/images/bp/f16.gif\"><br></center><br>  &emsp;&emsp;现在！该有的都有了，现在我们知道w5对于总误差的影响有多大了：</p>\n<p><center><br><img src=\"/images/bp/f17.gif\"><br></center><br>  &emsp;&emsp;我们现在要对w5这项权值做出调整，调整的依据是刚刚算出的误差值，通过加权的方式去调整，我们需要设定一个学习率来衡量误差对于调整过程的比例，本例中设为0.5：</p>\n<p><center><br><img src=\"/images/bp/f18.gif\"><br></center><br>  &emsp;&emsp;神奇的事情发生了，可以看到w5的权值由原来的0.3调整为0.25772292463736585，从调整的幅度上来看好像还挺有道理的，我们用相同的方法把所有的权值都调整一遍：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">//反向传播第一层</div><div class=\"line\">this.backward1 =function() &#123;\t</div><div class=\"line\">\tfor (var y = 0; y &lt; t.length; y++) &#123;</div><div class=\"line\">\t\tfor (var x = 0; x &lt; h.length; x++) &#123;</div><div class=\"line\">\t\t\tvar selfEffect = -1 * (t[y] - o[y]) * o[y] * (1 - o[y]) * h[x];</div><div class=\"line\">\t\t\tnW[1][x + y * v] = w[1][x + y * v] - lr * selfEffect;</div><div class=\"line\">\t\t\tconsole.info(&apos;w&apos; + parseInt(5 + x + y * v) + &quot;权重变化: &quot; + w[1][x + y * v] + &quot; =&gt; &quot; + nW[1][x + y * v]);</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div><div class=\"line\">---------------</div><div class=\"line\">w5权重变化: 0.3 =&gt; 0.25772292463736585</div><div class=\"line\">w6权重变化: 0.35 =&gt; 0.3075091952101869</div><div class=\"line\">w7权重变化: 0.4 =&gt; 0.413242963882813</div><div class=\"line\">w8权重变化: 0.45 =&gt; 0.46330991295770874</div></pre></td></tr></table></figure>\n<p>  &emsp;&emsp;OK,到目前为止，我们已经成功一半了，接下来需要更新w1~w4的权值，以w1为例，我们需要算出w1对于总误差的影响，依然通过链式法则求偏导：</p>\n<p><center><br><img src=\"/images/bp/f19.gif\"><br></center><br>  &emsp;&emsp;这里有一个情况出现了，我们的算式里第一项是描述h1节点对于总误差的影响，如何描述这个影响，直接求求不出啊？冷静，思路依然是将问题细分，我们可以看到模型中这个h1节点可以影响o1,也可以影响o2，所以这个过程可以看做h1对o1,o2的影响之和，下面我们开始计算：</p>\n<p><center><br><img src=\"/images/bp/f20.gif\"><br></center><br>  &emsp;&emsp;第1部分，这一部分其实又可以分为2个小部分，我们以计算o1例。在计算的时候有一个技巧，o1输出对于E0的影响其实就等于o1输出对于E_total的影响，所以可以用之前算过的值直接代入；由于out_o1是线性方程，h1对于out_o1的影响就等于其斜率w5：</p>\n<center>\n\n<p><img src=\"/images/bp/f21.gif\"><br><img src=\"/images/bp/f22.gif\"><br></p></center><br>  &emsp;&emsp;代入之前求得的值就可以求解第1部分：<p></p>\n<p><center><br><img src=\"/images/bp/f23.gif\"><br><img src=\"/images/bp/f24.gif\"><br><img src=\"/images/bp/f25.gif\"><br></center><br>  &emsp;&emsp;第2部分，就是对sigmoid函数求导，代入可以求解：</p>\n<p><center><br><img src=\"/images/bp/f26.gif\"><br></center><br>  &emsp;&emsp;第3部分，是对线性函数求导，求解：</p>\n<p><center><br><img src=\"/images/bp/f27.gif\"><br></center><br>  &emsp;&emsp;大功告成，我们将3部分数据相乘，并加上学习率，最终求解：</p>\n<p><center><br><img src=\"/images/bp/f28.gif\"><br><img src=\"/images/bp/f29.gif\"><br></center><br>  &emsp;&emsp;我们将其余的权重都求解：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div></pre></td><td class=\"code\"><pre><div class=\"line\">//反向传播第二层</div><div class=\"line\">this.backward2 = function() &#123;</div><div class=\"line\">\tvar f_1 = [];</div><div class=\"line\">\tvar f_2 = 0;</div><div class=\"line\">\tvar f_3 = 0;</div><div class=\"line\">\tvar _f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][0];</div><div class=\"line\">\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][2];</div><div class=\"line\">\tf_1.push(_f_1);</div><div class=\"line\">\t_f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][1];</div><div class=\"line\">\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][3];</div><div class=\"line\">\tf_1.push(_f_1);</div><div class=\"line\">\tfor (var y = 0; y &lt; h.length; y++) &#123;</div><div class=\"line\">\t\tf_2 = h[y] * (1 - h[y]);</div><div class=\"line\">\t\tfor (var z = 0; z &lt; i.length; z++) &#123;</div><div class=\"line\">\t\t\tf_3 = i[z];</div><div class=\"line\">\t\t\tnW[0][y + z * v] = w[0][y + z * v] - lr * (f_1[y] * f_2 * f_3);</div><div class=\"line\">\t\t\tconsole.info(&apos;w&apos; + parseInt(y + z * v) + &quot;权重变化: &quot; + w[1][y + z * v] + &quot; =&gt; &quot; + nW[1][y + z * v]);</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tw = nW;</div><div class=\"line\">&#125;;</div><div class=\"line\">--------------------</div><div class=\"line\">w0权重变化: 0.3 =&gt; 0.25772292463736585</div><div class=\"line\">w2权重变化: 0.4 =&gt; 0.413242963882813</div><div class=\"line\">w1权重变化: 0.35 =&gt; 0.3075091952101869</div><div class=\"line\">w3权重变化: 0.45 =&gt; 0.46330991295770874</div></pre></td></tr></table></figure></p>\n<p> &emsp;&emsp;目前为止，我们已经完成了训练，接下来我们来验证一下训练的成果。仍然将[0.15,0.1]作为输入层输入，我们看到通过新的权重计算后得到的结果是:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">预测值变化：0.7286638276265998,0.751601224586807 =&gt; 0.7185477013468267,0.7545430129300831</div></pre></td></tr></table></figure></p>\n<p> &emsp;&emsp;可以观察到o1越来越接近0.01,o2越来越接近0.99，OK，我们来循环10000次，观察训练后的结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">var test = new Neural();</div><div class=\"line\">var final_o=[];</div><div class=\"line\">for (var i = 0; i &lt; 10000; i++) &#123;</div><div class=\"line\">\ttest.forward();</div><div class=\"line\">\tvar old_o=[].concat(test.o);</div><div class=\"line\">\ttest.totalError();</div><div class=\"line\">\ttest.backward1();</div><div class=\"line\">\ttest.backward2();</div><div class=\"line\">\ttest.forward();</div><div class=\"line\">\tfinal_o=[].concat(test.o);\t</div><div class=\"line\">&#125;</div><div class=\"line\">console.info(&apos;最终预测值：&apos;+final_o);</div><div class=\"line\">-----------------------</div><div class=\"line\">最终预测值：0.015360963767399535,0.9845412722122693</div></pre></td></tr></table></figure></p>\n<p>  &emsp;&emsp;成功！</p>\n<p></p><h3 id=\"id6\">结语</h3><br>  &emsp;&emsp;我们已经模拟了最为简单的情况，可以想像如果增加输入层维度，并且增加隐含层层数，模型的拟合度会越来越高，但计算量也会指数倍增长。<br><!-- out_h1=0.595078473866134--><br><!-- out_o1=0.7286638276265998--><br><!--$$n_{h1}=i_1 * w_1 + i_2 * w_2 + b_1 * 1=0.15 * 0.1 + 0.1 * 0.2 + 0.35 * 1=0.385$$--><br><!--$$out_{h1}=\\frac {1} {1+exp^{(-n_h1)}}=\\frac {1} {1+exp^{(-0.385)}}=0.595078473866134$$--><br><!--$$E_{o1}=\\frac 1 2(o1 - out_{o1} )^2= \\frac 1 2(0.01 - 0.7286638276265998)^2=0.25823884856945756 $$--><br><!--$$E_{o2}=\\frac 1 2(o2 - out_{o2} )^2= \\frac 1 2(0.99 - 0.751601224586807)^2=0.028416988059255015 $$--><br><!--$$E_{total}=(E_{o1} + E_{o2})=(0.25823884856945756+0.028416988059255015)=0.2866558366287126 $$--><br><!--\\frac {\\partial E_{total}} {\\partial w_{5}} =\\frac {\\partial E_{total}} {\\partial out_{o1}} * \\frac {\\partial out_{o1}} {\\partial n_{1}} *{\\partial n_{1}} {\\partial w_{5}} --><br><!--\\frac {\\partial E_{total}} {\\partial out_{o1}} =\\frac {\\partial (\\frac 1 2(o_1 - out_{o1} )^2 + \\frac 1 2(o_2 - out_{o2} )^2) } {\\partial out_{o1}}=2 * \\frac 1 2 (o_1 - out_{o1})^{2-1} * -1 + 0--><br><!--\\frac {\\partial out_{o1}} {\\partial n_{o1}} =\\frac {\\partial (\\frac {1} {1+exp^{(-n_o1)}})} {\\partial n_{o1}} = --><br><!--f(x)'={(\\frac 1 {1+exp^{-x}})}'={(\\frac {exp^x} {1+exp^{x}})}'=\\frac {exp^x}{(exp^x + 1)^2}=f(x)*(1-f(x))--><br><!--\\frac {\\partial E_{total}} {\\partial w_{1}} = ( \\frac {\\partial E_{o1}} {\\partial out_{h1}} + \\frac {\\partial E_{o2}} {\\partial out_{h1}})*\\frac {\\partial out_{h1}} {\\partial n_{h1}} *\\frac {\\partial n_{h1}} {\\partial w_{1}} --><br><!--\\frac {\\partial E_{o1}} {\\partial out_{h1}} =\\frac {\\partial E_{o1}} {\\partial n_{h1}} * \\frac {\\partial n_{h1}} {\\partial out_{h1}} = \\frac {\\partial E_{total}} {\\partial out_{o1}} * \\frac {\\partial out_{o1}} {\\partial n_{h1}}* \\frac {\\partial n_{h1}} {\\partial out_{h1}}--><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a><!--\\frac {\\partial E_{o2}} {\\partial out_{h1}} =0.7186638276265997 * 0.19771285393515267 * 0.3=0.0426267229140047 --></h2>","excerpt":"","more":"<p><h2 id='id1' >人工智能</h2><br>  &emsp;&emsp;目前最火的技术莫过于人工智能，或者说机器学习。从IBM Watson到Google AlphaGo,人工智能仿佛已经冲出了实验室，在实际生活中发挥作用。面对如此高大上的技术，普通老百姓要如何去看待它，理解它的本质呢?沉着冷静别惊慌，本文将尽可能给你一个答案。</p>\n<p>  &emsp;&emsp;首先要知道机器学习的本质是算法，这里就会有好几种，比如：神经网络、支持向量机、朴素贝叶斯等等一堆。虽然算法很多，但他们主要解决的都是同一个问题—分类预测问题。为什么分类预测问题这么重要？因为机器学习的本质是重现人类学习的过程，这个过程可以大致分为两部分：1.定义一个事物，2.判断一个事物。如果一个机器可以对一个事物进行判断，判断的结果与人类的判断相似，那它近似的就是一个人工智能。</p>\n<p>  &emsp;&emsp;假设这样一个场景，我和机器都看到了一个苹果，按照之前对机器的训练如果他告诉我他看到了一个苹果，那说明这个机器是具有一定人工智能的，如果它还能告诉我这个苹果的产地，成熟度，净重，品种、颜色、气味特征等等….我也不会惊讶，因为这是描述一个苹果的特征，也是机器定义这是一个苹果的依据。你看，这里就出现了一个人类与机器的差异，我们学习一个事物并不需要太多维度的特征来描述一个事物，比如，在某某地区生长的、重量在这个范围的、颜色可能是这种的、可能有这些形状的、…（此处省略无限字，因为可以从无限个维度去描述一个苹果）,OK,这个东西叫苹果！我们只要摸过吃过看过，大概就知道啥是苹果，也不会和梨搞错，为什么！因为我们聪明，没错，我们的大脑做了定义和判断的工作并且是在我们无意识的情况下。从这个角度上来说，其实研究机器学习的本质其实是研究人类自己认识这个世界的过程。  </p>\n<p><h2 id='id2'>神经网络</h2><br>  &emsp;&emsp;本篇文章的主题就是人工神经网络中的反向传播算法（Back Propagation Algorithm，BP算法）。反向传播算法是实现人工神经网络（Neural Networks，NNs）中非常重要的技术，就是它让神经网络变的“智能”，本文将会利用最简单的NNs模型来模拟整个反向传播算法，并同时使用JavaScript来实现整个过程，文章的最后会提供程序给大家交流，这里需要声明一点，这个程序只是为了演示算法。好了，开始吧。<br>  &emsp;&emsp;首先神经网络的模型是这个样子的，这是一个简化到不能在简化的神经网络结构，图中的球模拟了神经元的细胞，线模拟了神经元的突触，简而言之它在用数学模型模拟我们的大脑：</p>\n<center> <img src=\"/images/bp/bp1.svg\"> </center>\n\n\n<p>  &emsp;&emsp;在左侧有i1,i2，表示输入层；最右侧有o1,o2,表示输出层。当我们在训练机器学习的时候，会把输入值和输出值都设定好，好比说，i1=0.15，i2=0.10；计算结果应该是o1=0.01,o2=0.99，如果训练是成功的，那当我输入相同的输入值时，结果应该也是相同的。是不是有点像我们在构造一个函数，而这个函数的计算过程我们并不能看到，这也是为什么很多人说神经网络是一个黑盒模型。我们需要在中间加入一层来描述其中转换的过程，由于是不可见的，这层叫隐含层h1,h2。现在我们需要初始化节点之间的连线，为这些连线加上随机的权值。这些初始化的权值会在之后的计算中被更新，事实上这些权值就是描述这个机器思考的模型。在计算的过程中，我们还会用到b1,b2，这称为偏置项，值永远是1，权值可以自由设置，这里我们设b1权值为0.35，b2权值为0.60。OK,现在这个模型变成了这样：</p>\n<center> <img src=\"/images/bp/bp2.svg\"> </center>\n\n<p>  &emsp;&emsp;好了，一切就绪，我们要开始算了！怎么算呢？整个算法的过程分为3个部分：前向传播、计算误差、反向传播，可以理解为我先试一下现在判断，与预期的判断做个比较，然后修正我的判断，下面就每个步骤详细说明一下。</p>\n<h3 id='id3'>前向传播</h3>\n\n<p>  &emsp;&emsp;首先我们会从模型的左侧计算到右侧，这个方向称为前向。这一步可以分为2步，第1步是简单的加权相加或者叫做线性回归，第2步是代入一个激活函数，激活函数的作用是将线性函数表达为非线性函数，它会把值挤压进一个(0,1)区间的范围作为规范化处理，同时还可以反应出对象的条件概率，激活函数使用sigmoid函数,exp函数表示了以e为底的指数函数: </p>\n<p><center> <img src=\"/images/bp/f1.gif\"> </center><br>    <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">//激活函数</div><div class=\"line\">this.sigmoid=function(z) &#123;</div><div class=\"line\">\treturn 1 / (1 + Math.exp(-z));</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>  &emsp;&emsp;第1步，计算线性回归：    </p>\n<p><center> <img src=\"/images/bp/f2.gif\"> </center><br>  &emsp;&emsp;第2步，激活：</p>\n<p><center> <img src=\"/images/bp/f3.svg\"> </center><br>  &emsp;&emsp;现在我们就计算出了h1节点的值，用相同的方法，我们计算出h2，o1，o2节点:</p>\n<p><center><br><img src=\"/images/bp/f4.gif\"><br><img src=\"/images/bp/f5.gif\"><br><img src=\"/images/bp/f6.gif\"><br></center><br>  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">//前向传播</div><div class=\"line\">this.forward=function() &#123;</div><div class=\"line\">  //隐含层</div><div class=\"line\">  for (var x = 0; x &lt; i.length; x++) &#123;</div><div class=\"line\">    h[x] = sigmoid(i[0] * w[0][x * v] + i[1] * w[0][x * v + 1] + b[0]);</div><div class=\"line\">  &#125;</div><div class=\"line\">  //输出层</div><div class=\"line\">  for (var y = 0; y &lt; i.length; y++) &#123;</div><div class=\"line\">    o[y] = sigmoid(h[0] * w[1][y * v] + h[1] * w[1][y * v + 1] + b[1]);</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>  &emsp;&emsp;可以看到计算的结果和我们设定的结果(0.01,0.99)有很大的误差，这很大程度上是由于权值初始化的时候，接下来我们需要减小这个误差。  </p>\n<p><h3 id='id4'>计算总误差</h3><br>  &emsp;&emsp;误差计算通过平方误差函数为每个节点计算误差，然后将这些误差相加计算总误差:</p>\n<p><center><img src=\"/images/bp/f7.gif\"></center><br>    <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">//计算总误差</div><div class=\"line\">this.totalError=function() &#123;</div><div class=\"line\">  for (var x = 0; x &lt; t.length; x++) &#123;</div><div class=\"line\">    e[x] = squareErr(t[x], o[x]);</div><div class=\"line\">    te += e[x];</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>  &emsp;&emsp;我们分别计算o1，o2的误差值，并将他们相加:</p>\n<p><center><br><img src=\"/images/bp/f8.gif\"><br><img src=\"/images/bp/f9.gif\"><br><img src=\"/images/bp/f10.gif\"><br></center></p>\n<p><h3 id='id5'>反向传播</h3><br>  &emsp;&emsp;现在我们从模型的右侧开始向左侧计算，目标是要使得总误差值变小。我们首先计算w5这一路，这里需要一个方法来计算w5对总误差的影响，刚好导数的意义是描述参数变化对函数造成影响的变化率，或者叫斜率。所以我们想知道w5对总误差带来的变化率可以通过求w5的偏导来计算。然而单纯去算是算不出的，要使用连式法则来分解计算步骤（宏观上看这些中间变量都可以被约分约掉）,下面我们就将这个问题分为等式右侧的3部分去求解：</p>\n<p><center><br><img src=\"/images/bp/f11.gif\"><br></center><br>  &emsp;&emsp;第1部分，o1的输出对于总误差的影响，由于我们不关心o2的输出，所以整个右侧可以计算为0，然后利用求导公式就可以算出：</p>\n<p><center><br><img src=\"/images/bp/f12.gif\"><br></center><br>  &emsp;&emsp;代入之前的数据可以求解：</p>\n<p><center><br><img src=\"/images/bp/f13.gif\"><br></center><br> &emsp;&emsp;第2部分，这里其实就是对于激活函数来说，o1输出对它的影响，由于激活函数是sigmoid，其求导公式推导如下：</p>\n<p><center><br><img src=\"/images/bp/f14.gif\"><br></center><br>  &emsp;&emsp;所以我们可以得到第二部分的求解：</p>\n<p><center><br><img src=\"/images/bp/f15.gif\"><br></center><br>  &emsp;&emsp;第3部分，w5对于线性方程的影响，其求导结果就是w5的斜率：</p>\n<p><center><br><img src=\"/images/bp/f16.gif\"><br></center><br>  &emsp;&emsp;现在！该有的都有了，现在我们知道w5对于总误差的影响有多大了：</p>\n<p><center><br><img src=\"/images/bp/f17.gif\"><br></center><br>  &emsp;&emsp;我们现在要对w5这项权值做出调整，调整的依据是刚刚算出的误差值，通过加权的方式去调整，我们需要设定一个学习率来衡量误差对于调整过程的比例，本例中设为0.5：</p>\n<p><center><br><img src=\"/images/bp/f18.gif\"><br></center><br>  &emsp;&emsp;神奇的事情发生了，可以看到w5的权值由原来的0.3调整为0.25772292463736585，从调整的幅度上来看好像还挺有道理的，我们用相同的方法把所有的权值都调整一遍：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">//反向传播第一层</div><div class=\"line\">this.backward1 =function() &#123;\t</div><div class=\"line\">\tfor (var y = 0; y &lt; t.length; y++) &#123;</div><div class=\"line\">\t\tfor (var x = 0; x &lt; h.length; x++) &#123;</div><div class=\"line\">\t\t\tvar selfEffect = -1 * (t[y] - o[y]) * o[y] * (1 - o[y]) * h[x];</div><div class=\"line\">\t\t\tnW[1][x + y * v] = w[1][x + y * v] - lr * selfEffect;</div><div class=\"line\">\t\t\tconsole.info(&apos;w&apos; + parseInt(5 + x + y * v) + &quot;权重变化: &quot; + w[1][x + y * v] + &quot; =&gt; &quot; + nW[1][x + y * v]);</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div><div class=\"line\">---------------</div><div class=\"line\">w5权重变化: 0.3 =&gt; 0.25772292463736585</div><div class=\"line\">w6权重变化: 0.35 =&gt; 0.3075091952101869</div><div class=\"line\">w7权重变化: 0.4 =&gt; 0.413242963882813</div><div class=\"line\">w8权重变化: 0.45 =&gt; 0.46330991295770874</div></pre></td></tr></table></figure>\n<p>  &emsp;&emsp;OK,到目前为止，我们已经成功一半了，接下来需要更新w1~w4的权值，以w1为例，我们需要算出w1对于总误差的影响，依然通过链式法则求偏导：</p>\n<p><center><br><img src=\"/images/bp/f19.gif\"><br></center><br>  &emsp;&emsp;这里有一个情况出现了，我们的算式里第一项是描述h1节点对于总误差的影响，如何描述这个影响，直接求求不出啊？冷静，思路依然是将问题细分，我们可以看到模型中这个h1节点可以影响o1,也可以影响o2，所以这个过程可以看做h1对o1,o2的影响之和，下面我们开始计算：</p>\n<p><center><br><img src=\"/images/bp/f20.gif\"><br></center><br>  &emsp;&emsp;第1部分，这一部分其实又可以分为2个小部分，我们以计算o1例。在计算的时候有一个技巧，o1输出对于E0的影响其实就等于o1输出对于E_total的影响，所以可以用之前算过的值直接代入；由于out_o1是线性方程，h1对于out_o1的影响就等于其斜率w5：</p>\n<center>\n\n<p><img src=\"/images/bp/f21.gif\"><br><img src=\"/images/bp/f22.gif\"><br></center><br>  &emsp;&emsp;代入之前求得的值就可以求解第1部分：</p>\n<p><center><br><img src=\"/images/bp/f23.gif\"><br><img src=\"/images/bp/f24.gif\"><br><img src=\"/images/bp/f25.gif\"><br></center><br>  &emsp;&emsp;第2部分，就是对sigmoid函数求导，代入可以求解：</p>\n<p><center><br><img src=\"/images/bp/f26.gif\"><br></center><br>  &emsp;&emsp;第3部分，是对线性函数求导，求解：</p>\n<p><center><br><img src=\"/images/bp/f27.gif\"><br></center><br>  &emsp;&emsp;大功告成，我们将3部分数据相乘，并加上学习率，最终求解：</p>\n<p><center><br><img src=\"/images/bp/f28.gif\"><br><img src=\"/images/bp/f29.gif\"><br></center><br>  &emsp;&emsp;我们将其余的权重都求解：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div></pre></td><td class=\"code\"><pre><div class=\"line\">//反向传播第二层</div><div class=\"line\">this.backward2 = function() &#123;</div><div class=\"line\">\tvar f_1 = [];</div><div class=\"line\">\tvar f_2 = 0;</div><div class=\"line\">\tvar f_3 = 0;</div><div class=\"line\">\tvar _f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][0];</div><div class=\"line\">\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][2];</div><div class=\"line\">\tf_1.push(_f_1);</div><div class=\"line\">\t_f_1 = -1 * (t[0] - o[0]) * o[0] * (1 - o[0]) * w[1][1];</div><div class=\"line\">\t_f_1 += -1 * (t[1] - o[1]) * o[1] * (1 - o[1]) * w[1][3];</div><div class=\"line\">\tf_1.push(_f_1);</div><div class=\"line\">\tfor (var y = 0; y &lt; h.length; y++) &#123;</div><div class=\"line\">\t\tf_2 = h[y] * (1 - h[y]);</div><div class=\"line\">\t\tfor (var z = 0; z &lt; i.length; z++) &#123;</div><div class=\"line\">\t\t\tf_3 = i[z];</div><div class=\"line\">\t\t\tnW[0][y + z * v] = w[0][y + z * v] - lr * (f_1[y] * f_2 * f_3);</div><div class=\"line\">\t\t\tconsole.info(&apos;w&apos; + parseInt(y + z * v) + &quot;权重变化: &quot; + w[1][y + z * v] + &quot; =&gt; &quot; + nW[1][y + z * v]);</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tw = nW;</div><div class=\"line\">&#125;;</div><div class=\"line\">--------------------</div><div class=\"line\">w0权重变化: 0.3 =&gt; 0.25772292463736585</div><div class=\"line\">w2权重变化: 0.4 =&gt; 0.413242963882813</div><div class=\"line\">w1权重变化: 0.35 =&gt; 0.3075091952101869</div><div class=\"line\">w3权重变化: 0.45 =&gt; 0.46330991295770874</div></pre></td></tr></table></figure></p>\n<p> &emsp;&emsp;目前为止，我们已经完成了训练，接下来我们来验证一下训练的成果。仍然将[0.15,0.1]作为输入层输入，我们看到通过新的权重计算后得到的结果是:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">预测值变化：0.7286638276265998,0.751601224586807 =&gt; 0.7185477013468267,0.7545430129300831</div></pre></td></tr></table></figure></p>\n<p> &emsp;&emsp;可以观察到o1越来越接近0.01,o2越来越接近0.99，OK，我们来循环10000次，观察训练后的结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">var test = new Neural();</div><div class=\"line\">var final_o=[];</div><div class=\"line\">for (var i = 0; i &lt; 10000; i++) &#123;</div><div class=\"line\">\ttest.forward();</div><div class=\"line\">\tvar old_o=[].concat(test.o);</div><div class=\"line\">\ttest.totalError();</div><div class=\"line\">\ttest.backward1();</div><div class=\"line\">\ttest.backward2();</div><div class=\"line\">\ttest.forward();</div><div class=\"line\">\tfinal_o=[].concat(test.o);\t</div><div class=\"line\">&#125;</div><div class=\"line\">console.info(&apos;最终预测值：&apos;+final_o);</div><div class=\"line\">-----------------------</div><div class=\"line\">最终预测值：0.015360963767399535,0.9845412722122693</div></pre></td></tr></table></figure></p>\n<p>  &emsp;&emsp;成功！</p>\n<p><h3 id='id6'>结语</h3><br>  &emsp;&emsp;我们已经模拟了最为简单的情况，可以想像如果增加输入层维度，并且增加隐含层层数，模型的拟合度会越来越高，但计算量也会指数倍增长。<br><!-- out_h1=0.595078473866134--><br><!-- out_o1=0.7286638276265998--><br><!--$$n_{h1}=i_1 * w_1 + i_2 * w_2 + b_1 * 1=0.15 * 0.1 + 0.1 * 0.2 + 0.35 * 1=0.385$$--><br><!--$$out_{h1}=\\frac {1} {1+exp^{(-n_h1)}}=\\frac {1} {1+exp^{(-0.385)}}=0.595078473866134$$--><br><!--$$E_{o1}=\\frac 1 2(o1 - out_{o1} )^2= \\frac 1 2(0.01 - 0.7286638276265998)^2=0.25823884856945756 $$--><br><!--$$E_{o2}=\\frac 1 2(o2 - out_{o2} )^2= \\frac 1 2(0.99 - 0.751601224586807)^2=0.028416988059255015 $$--><br><!--$$E_{total}=(E_{o1} + E_{o2})=(0.25823884856945756+0.028416988059255015)=0.2866558366287126 $$--><br><!--\\frac {\\partial E_{total}} {\\partial w_{5}} =\\frac {\\partial E_{total}} {\\partial out_{o1}} * \\frac {\\partial out_{o1}} {\\partial n_{1}} *{\\partial n_{1}} {\\partial w_{5}} --><br><!--\\frac {\\partial E_{total}} {\\partial out_{o1}} =\\frac {\\partial (\\frac 1 2(o_1 - out_{o1} )^2 + \\frac 1 2(o_2 - out_{o2} )^2) } {\\partial out_{o1}}=2 * \\frac 1 2 (o_1 - out_{o1})^{2-1} * -1 + 0--><br><!--\\frac {\\partial out_{o1}} {\\partial n_{o1}} =\\frac {\\partial (\\frac {1} {1+exp^{(-n_o1)}})} {\\partial n_{o1}} = --><br><!--f(x)'={(\\frac 1 {1+exp^{-x}})}'={(\\frac {exp^x} {1+exp^{x}})}'=\\frac {exp^x}{(exp^x + 1)^2}=f(x)*(1-f(x))--><br><!--\\frac {\\partial E_{total}} {\\partial w_{1}} = ( \\frac {\\partial E_{o1}} {\\partial out_{h1}} + \\frac {\\partial E_{o2}} {\\partial out_{h1}})*\\frac {\\partial out_{h1}} {\\partial n_{h1}} *\\frac {\\partial n_{h1}} {\\partial w_{1}} --><br><!--\\frac {\\partial E_{o1}} {\\partial out_{h1}} =\\frac {\\partial E_{o1}} {\\partial n_{h1}} * \\frac {\\partial n_{h1}} {\\partial out_{h1}} = \\frac {\\partial E_{total}} {\\partial out_{o1}} * \\frac {\\partial out_{o1}} {\\partial n_{h1}}* \\frac {\\partial n_{h1}} {\\partial out_{h1}}--></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a><!--\\frac {\\partial E_{o2}} {\\partial out_{h1}} =0.7186638276265997 * 0.19771285393515267 * 0.3=0.0426267229140047 --></h2>"}],"PostAsset":[],"PostCategory":[{"post_id":"cj0ubhjxx00007u8g3lklsgbe","category_id":"cj0ubhjyu00037u8g0p29lrbn","_id":"cj0ubhjzd00067u8gk6bwvoqw"}],"PostTag":[{"post_id":"cj0ubhjxx00007u8g3lklsgbe","tag_id":"cj0ubhjz000047u8gmgjek2s1","_id":"cj0ubhjzg00077u8g7vh4r5qq"},{"post_id":"cj0ubhjxx00007u8g3lklsgbe","tag_id":"cj0ubhjz500057u8gdv3pj358","_id":"cj0ubhjzg00087u8gcdkfufn4"}],"Tag":[{"name":"神经网络","_id":"cj0ubhjz000047u8gmgjek2s1"},{"name":"机器学习","_id":"cj0ubhjz500057u8gdv3pj358"}]}}